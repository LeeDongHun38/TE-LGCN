{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install gensim"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "g_IJGiIqRYLW",
    "outputId": "01389dfd-6eb3-4da2-c413-8965038b81fa"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gensim\n",
      "Successfully installed gensim-4.4.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bEmdCKPOUsI",
    "outputId": "1a1b97ad-9a74-46ed-903f-c93675253ce8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# =========================================================\n",
    "# 1. \ud658\uacbd \uc124\uc815 \ubc0f \uc2dc\ub4dc \uace0\uc815\n",
    "# =========================================================\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# \uacbd\ub85c \uc124\uc815 (Step 0\uc5d0\uc11c \uc800\uc7a5\ud55c processed_data \ud3f4\ub354 \uacbd\ub85c)\n",
    "base_path = \"/content/drive/MyDrive/unstructured\"\n",
    "data_path = f\"{base_path}/k5_filtered\"\n",
    "movie_final_path = f\"{base_path}/movie_data_final_clean.csv\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJ_IGuIDRS89",
    "outputId": "50c2dc5a-217b-4b88-9239-3daabb62b69e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Lamda2 = 0 \uc778 \uacbd\uc6b0**"
   ],
   "metadata": {
    "id": "Cs-KeIG0Tf2h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "# 2. \ub370\uc774\ud130 \ub85c\ub4dc (Pre-split Data \uc0ac\uc6a9)\n",
    "# =========================================================\n",
    "if not os.path.exists(data_path) or not os.path.exists(movie_final_path):\n",
    "    print(\"Error: \ub370\uc774\ud130 \uacbd\ub85c\ub97c \ud655\uc778\ud574\uc8fc\uc138\uc694.\")\n",
    "else:\n",
    "    # 1. \ub370\uc774\ud130 \uc77d\uae30\n",
    "    train_df = pd.read_csv(f\"{data_path}/train.csv\")\n",
    "    val_df   = pd.read_csv(f\"{data_path}/val.csv\")\n",
    "    test_df  = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "    # 2. \ub9e4\ud551 \uc815\ubcf4 \ub85c\ub4dc\n",
    "    with open(f\"{data_path}/user2idx.pkl\", 'rb') as f: user2idx = pickle.load(f)\n",
    "    with open(f\"{data_path}/item2idx.pkl\", 'rb') as f: item2idx = pickle.load(f)\n",
    "\n",
    "    n_users = len(user2idx)\n",
    "    n_items = len(item2idx)\n",
    "\n",
    "    print(f\"\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: {n_users}, Item: {n_items}\")\n",
    "    print(f\"\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: {len(train_df)}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 3. \ub370\uc774\ud130 \ubd84\ub9ac (Positive vs Hard Negative)\n",
    "    # =========================================================\n",
    "    # 1) Positive Data (4\uc810 \uc774\uc0c1): \uadf8\ub798\ud504 \uc5f0\uacb0 \ubc0f \uc815\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_pos_df = train_df[train_df['rating'] >= 4.0].copy()\n",
    "\n",
    "    # 2) Hard Negative Data (2\uc810 \uc774\ud558): \uc624\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_neg_df = train_df[train_df['rating'] <= 2.0].copy()\n",
    "\n",
    "    print(f\"Positive Interactions (Graph\uc6a9): {len(train_pos_df)}\")\n",
    "    print(f\"Hard Negative Interactions: {len(train_neg_df)}\")\n",
    "\n",
    "    # \ub515\uc154\ub108\ub9ac \uc0dd\uc131\n",
    "    # Positive: \uc720\uc800\uac00 \uc88b\uc544\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d\n",
    "    user_pos_items = train_pos_df.groupby(\"user\")[\"item\"].apply(set).to_dict()\n",
    "\n",
    "    # Hard Negative: \uc720\uc800\uac00 \uc2eb\uc5b4\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d (\uc0d8\ud50c\ub9c1 \ub54c \uc0ac\uc6a9)\n",
    "    user_hard_neg_items = train_neg_df.groupby(\"user\")[\"item\"].apply(list).to_dict()\n",
    "\n",
    "    # =========================================================\n",
    "    # 4. Doc2Vec \ud559\uc2b5 \ubc0f \ub9e4\ud2b8\ub9ad\uc2a4 \uc0dd\uc131 (Feature Extraction)\n",
    "    # =========================================================\n",
    "    print(\"\\n=== Doc2Vec Training ===\")\n",
    "    movie_df = pd.read_csv(movie_final_path)\n",
    "    movie_df['overview_clean'] = movie_df['overview_clean'].fillna('unknown')\n",
    "\n",
    "    # TaggedDocument \uc0dd\uc131 (ID\ub294 \uc6d0\ubcf8 movieId \uc0ac\uc6a9 -> \ub098\uc911\uc5d0 item2idx\ub85c \ub9e4\ud551)\n",
    "    documents = [TaggedDocument(str(row['overview_clean']).split(), [str(row['movieId'])])\n",
    "                 for _, row in movie_df.iterrows()]\n",
    "\n",
    "    # LightGCN \ucc28\uc6d0(64)\uacfc \uc77c\uce58\uc2dc\ud0b4\n",
    "    d2v_model = Doc2Vec(documents, vector_size=64, window=5, min_count=1, workers=4, epochs=20, seed=42)\n",
    "\n",
    "    # Embedding Matrix \uc0dd\uc131 (item_idx \uc21c\uc11c\uc5d0 \ub9de\uac8c \uc815\ub82c)\n",
    "    doc2vec_weights = np.zeros((n_items, 64))\n",
    "    cnt = 0\n",
    "    for movie_id, idx in item2idx.items():\n",
    "        # Doc2Vec \ubaa8\ub378\uc5d0 \ud574\ub2f9 \uc601\ud654 ID\uac00 \uc788\ub294\uc9c0 \ud655\uc778\n",
    "        if str(movie_id) in d2v_model.dv:\n",
    "            doc2vec_weights[idx] = d2v_model.dv[str(movie_id)]\n",
    "            cnt += 1\n",
    "        else:\n",
    "            # \uc5c6\uc73c\uba74 \ub79c\ub364 \ucd08\uae30\ud654 (\uc791\uc740 \uac12)\n",
    "            doc2vec_weights[idx] = np.random.normal(0, 0.01, 64)\n",
    "\n",
    "    doc2vec_weights = torch.FloatTensor(doc2vec_weights).to(device)\n",
    "    print(f\"Doc2Vec Matrix Created. Mapped: {cnt}/{n_items}\")\n",
    "\n",
    "\n",
    "    # Save Doc2Vec embeddings to disk for reuse\n",
    "    doc2vec_save_path = f\"{base_path}/doc2vec_embeddings_64d.pkl\"\n",
    "    with open(doc2vec_save_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'embeddings': doc2vec_weights.cpu().numpy(),\n",
    "            'item2idx': item2idx,\n",
    "            'n_items': n_items,\n",
    "            'vector_size': 64,\n",
    "            'created_at': str(pd.Timestamp.now())\n",
    "        }, f)\n",
    "    print(f\"\u2705 Doc2Vec embeddings saved to: {doc2vec_save_path}\")\n",
    "    # =========================================================\n",
    "    # 5. LightGCN\uc6a9 \uc778\uc811\ud589\ub82c \uc0dd\uc131 (Positive \ub370\uc774\ud130\ub9cc \uc0ac\uc6a9!)\n",
    "    # =========================================================\n",
    "    def get_adj_mat(n_users, n_items, pos_df):\n",
    "        \"\"\"\n",
    "        \ubc18\ub4dc\uc2dc 4\uc810 \uc774\uc0c1\uc778 pos_df\ub9cc \ub123\uc5b4\uc11c \uadf8\ub798\ud504\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud568\n",
    "        \"\"\"\n",
    "        n_nodes = n_users + n_items\n",
    "        user_np = pos_df['user'].values\n",
    "        item_np = pos_df['item'].values\n",
    "\n",
    "        R = sp.coo_matrix((np.ones(len(user_np)), (user_np, item_np)), shape=(n_users, n_items))\n",
    "\n",
    "        top_part = sp.hstack([sp.csr_matrix((n_users, n_users)), R])\n",
    "        bot_part = sp.hstack([R.T, sp.csr_matrix((n_items, n_items))])\n",
    "        A = sp.vstack([top_part, bot_part])\n",
    "\n",
    "        rowsum = np.array(A.sum(1))\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "\n",
    "        norm_adj = d_mat_inv_sqrt.dot(A).dot(d_mat_inv_sqrt).tocoo()\n",
    "        indices = torch.LongTensor(np.vstack((norm_adj.row, norm_adj.col)))\n",
    "        values = torch.FloatTensor(norm_adj.data)\n",
    "\n",
    "        return torch.sparse_coo_tensor(indices, values, torch.Size(norm_adj.shape)).to(device)\n",
    "\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\")\n",
    "    Adj_Matrix = get_adj_mat(n_users, n_items, train_pos_df)\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 6. \ubaa8\ub378 \uc815\uc758 (LightGCN with Doc2Vec Init)\n",
    "    # =========================================================\n",
    "    class LightGCN_Doc2Vec(nn.Module):\n",
    "        def __init__(self, n_users, n_items, dim, layers, A_hat, doc2vec_weights):\n",
    "            super().__init__()\n",
    "            self.n_users = n_users\n",
    "            self.n_items = n_items\n",
    "            self.dim = dim\n",
    "            self.layers = layers\n",
    "            self.A_hat = A_hat\n",
    "\n",
    "            # User\ub294 \ub79c\ub364 \ucd08\uae30\ud654\n",
    "            self.user_emb = nn.Embedding(n_users, dim)\n",
    "            nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "\n",
    "            # [\ud575\uc2ec] Item\uc740 Doc2Vec\uc73c\ub85c \ucd08\uae30\ud654 (freeze=False: \ud559\uc2b5 \uac00\ub2a5)\n",
    "            self.item_emb = nn.Embedding.from_pretrained(doc2vec_weights, freeze=False)\n",
    "\n",
    "            # Content Loss \uacc4\uc0b0\uc6a9 \uace0\uc815 \ubca1\ud130 (Buffer) - \ud559\uc2b5 \uc548 \ub428\n",
    "            self.register_buffer('fixed_doc2vec', doc2vec_weights.clone().detach())\n",
    "\n",
    "        def get_all_embeddings(self):\n",
    "            users = self.user_emb.weight\n",
    "            items = self.item_emb.weight\n",
    "            all_emb = torch.cat([users, items], dim=0)\n",
    "\n",
    "            embs = [all_emb]\n",
    "            for _ in range(self.layers):\n",
    "                all_emb = torch.sparse.mm(self.A_hat, all_emb)\n",
    "                embs.append(all_emb)\n",
    "\n",
    "            out = torch.stack(embs, dim=0).mean(dim=0)\n",
    "            return out[:self.n_users], out[self.n_users:]\n",
    "\n",
    "    # =========================================================\n",
    "    # 7. Loss & Sampling (Hard Negative + Content Loss)\n",
    "    # =========================================================\n",
    "    def sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5):\n",
    "        users = np.random.choice(list(user_pos_items.keys()), size=batch_size)\n",
    "        pos = []\n",
    "        neg = []\n",
    "\n",
    "        for u in users:\n",
    "            # Positive Sampling\n",
    "            pos.append(np.random.choice(list(user_pos_items[u])))\n",
    "\n",
    "            # Hard Negative Sampling (50% \ud655\ub960)\n",
    "            if (u in user_hard_neg_items) and (len(user_hard_neg_items[u]) > 0) and (random.random() < hard_prob):\n",
    "                neg.append(np.random.choice(user_hard_neg_items[u]))\n",
    "            else:\n",
    "                # Random Negative\n",
    "                while True:\n",
    "                    n = np.random.randint(0, n_items)\n",
    "                    if n not in user_pos_items[u]:\n",
    "                        neg.append(n); break\n",
    "\n",
    "        return (torch.LongTensor(users).to(device),\n",
    "                torch.LongTensor(pos).to(device),\n",
    "                torch.LongTensor(neg).to(device))\n",
    "\n",
    "    def bpr_loss_with_content(u_f, i_pos_f, i_neg_f, u_0, i_pos_0, i_neg_0, fixed_vec, lambda1, lambda2):\n",
    "        \"\"\"\n",
    "        u_f, i_pos_f, i_neg_f : \uc804\ud30c\ub41c \uc784\ubca0\ub529 (BPR\uc6a9)\n",
    "        u_0, i_pos_0, i_neg_0 : \ucd08\uae30 \uc784\ubca0\ub529 (Regularization\uc6a9)\n",
    "        fixed_vec             : \uace0\uc815\ub41c Doc2Vec \ubca1\ud130 (Content Loss\uc6a9)\n",
    "        \"\"\"\n",
    "        # 1. BPR Loss\n",
    "        pos_scores = (u_f * i_pos_f).sum(dim=1)\n",
    "        neg_scores = (u_f * i_neg_f).sum(dim=1)\n",
    "        bpr_loss = torch.mean(torch.nn.functional.softplus(-(pos_scores - neg_scores)))\n",
    "\n",
    "        # 2. L2 Regularization (E^0 \uae30\uc900)\n",
    "        reg_loss = 0.5 * (u_0.norm(2).pow(2) + i_pos_0.norm(2).pow(2) + i_neg_0.norm(2).pow(2)) / u_0.size(0)\n",
    "\n",
    "        # 3. Content Loss (E^0 vs Fixed Doc2Vec)\n",
    "        content_loss = F.mse_loss(i_pos_0, fixed_vec)\n",
    "\n",
    "        return bpr_loss + lambda1 * reg_loss + lambda2 * content_loss\n",
    "\n",
    "    # =========================================================\n",
    "    # 8. \ud3c9\uac00 \ud568\uc218 (Precision, Recall, NDCG, HitRate)\n",
    "    # =========================================================\n",
    "    def ndcg_at_k(rank, k):\n",
    "        if rank is None or rank >= k: return 0.0\n",
    "        return 1.0 / math.log2(rank + 2)\n",
    "\n",
    "    def evaluate(model, df_eval, k=10):\n",
    "        model.eval()\n",
    "        users_final, items_final = model.get_all_embeddings()\n",
    "        hits, ndcg, precision, recall, total_users = 0, 0, 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for u_idx, group in df_eval.groupby('user'):\n",
    "                total_users += 1\n",
    "                target_items = set(group['item'].values)\n",
    "\n",
    "                scores = torch.matmul(users_final[u_idx], items_final.t())\n",
    "\n",
    "                # Train\uc5d0\uc11c \ubcf8 \uc544\uc774\ud15c(Positive Only)\uc740 \ub9c8\uc2a4\ud0b9\n",
    "                if u_idx in user_pos_items:\n",
    "                    scores[list(user_pos_items[u_idx])] = -1e9\n",
    "\n",
    "                _, topk = torch.topk(scores, k)\n",
    "                topk = topk.cpu().tolist()\n",
    "\n",
    "                num_correct = 0\n",
    "                dcg, idcg = 0.0, 0.0\n",
    "\n",
    "                for i, item_id in enumerate(topk):\n",
    "                    if item_id in target_items:\n",
    "                        num_correct += 1\n",
    "                        dcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                num_targets = len(target_items)\n",
    "                for i in range(min(num_targets, k)):\n",
    "                    idcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                if num_correct > 0: hits += 1\n",
    "                precision += num_correct / k\n",
    "                recall += num_correct / num_targets\n",
    "                if idcg > 0: ndcg += dcg / idcg\n",
    "\n",
    "        return {'HitRate': hits/total_users, 'Precision': precision/total_users, 'Recall': recall/total_users, 'NDCG': ndcg/total_users}\n",
    "\n",
    "    # =========================================================\n",
    "    # 9. \ud559\uc2b5 \uc2e4\ud589 (Best Model Selection \uc801\uc6a9)\n",
    "    # =========================================================\n",
    "    dim = 64\n",
    "    layers = 3\n",
    "    batch_size = 1024\n",
    "    epochs = 50\n",
    "    lr = 1e-3\n",
    "\n",
    "    # [\uc124\uc815] \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\n",
    "    lambda1 = 1e-5  # Reg (Base \uc2e4\ud5d8 \uacb0\uacfc \ubc18\uc601)\n",
    "    lambda2 = 0     # Content Loss (Doc2Vec Init\ub9cc \uc4f0\ub824\uba74 0, \uaddc\uc81c\ud558\ub824\uba74 1e-3 \ub4f1)\n",
    "\n",
    "    model = LightGCN_Doc2Vec(n_users, n_items, dim, layers, Adj_Matrix, doc2vec_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Best Model \uc800\uc7a5 \ubcc0\uc218\n",
    "    best_recall = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_path = \"best_doc2vec_lightgcn.pt\"\n",
    "\n",
    "    print(f\"\\n=== Training Start (Lambda2={lambda2}, Hard Negative Applied) ===\")\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # \ubc30\uce58 \uc218\ub294 Positive Data \uae30\uc900\n",
    "        num_batches = len(train_pos_df) // batch_size + 1\n",
    "\n",
    "        for _ in range(num_batches):\n",
    "            # 1. \uc0d8\ud50c\ub9c1 (Hard Negative \ud3ec\ud568)\n",
    "            users, pos, neg = sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5)\n",
    "\n",
    "            # 2. \uc804\ud30c (BPR \uc6a9)\n",
    "            u_final, i_final = model.get_all_embeddings()\n",
    "            u_f = u_final[users]\n",
    "            i_pos_f = i_final[pos]\n",
    "            i_neg_f = i_final[neg]\n",
    "\n",
    "            # 3. \ucd08\uae30\uac12 (Reg & Content \uc6a9)\n",
    "            u_0 = model.user_emb.weight[users]\n",
    "            i_pos_0 = model.item_emb.weight[pos]\n",
    "            i_neg_0 = model.item_emb.weight[neg]\n",
    "\n",
    "            # 4. \uace0\uc815\ub41c Doc2Vec \ucd94\ucd9c\n",
    "            fixed_vec = model.fixed_doc2vec[pos]\n",
    "\n",
    "            # 5. Loss \uacc4\uc0b0\n",
    "            loss = bpr_loss_with_content(u_f, i_pos_f, i_neg_f,\n",
    "                                         u_0, i_pos_0, i_neg_0,\n",
    "                                         fixed_vec, lambda1, lambda2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # \ub9e4 Epoch\ub9c8\ub2e4 Validation \ud3c9\uac00\n",
    "        val_metrics = evaluate(model, val_df, k=10)\n",
    "        current_recall = val_metrics['Recall']\n",
    "\n",
    "        print(f\"[Epoch {epoch:02d}] Loss: {total_loss/num_batches:.4f} | Val Recall: {current_recall:.4f} | NDCG: {val_metrics['NDCG']:.4f}\")\n",
    "\n",
    "        if current_recall > best_recall:\n",
    "            best_recall = current_recall\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"   >>> Best Model Updated!\")\n",
    "\n",
    "    print(f\"\\n=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: {best_epoch}, Best Val Recall: {best_recall:.4f} ===\")\n",
    "\n",
    "    # Final Test with Best Model\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    test_metrics = evaluate(model, test_df, k=10)\n",
    "    print(\"\\n=== Final Test Result (Best Model) ===\")\n",
    "    print(f\"Hit: {test_metrics['HitRate']:.4f}, Prec: {test_metrics['Precision']:.4f}, Recall: {test_metrics['Recall']:.4f}, NDCG: {test_metrics['NDCG']:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f28OdvBSElh",
    "outputId": "af611954-1955-4738-b1ff-12b646d32d49"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: 671, Item: 3485\n",
      "\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: 88595\n",
      "Positive Interactions (Graph\uc6a9): 46243\n",
      "Hard Negative Interactions: 11327\n",
      "\n",
      "=== Doc2Vec Training ===\n",
      "Doc2Vec Matrix Created. Mapped: 3485/3485\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-1434115670.py:88: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Training Start (Lambda2=0, Hard Negative Applied) ===\n",
      "[Epoch 01] Loss: 0.6464 | Val Recall: 0.1036 | NDCG: 0.0558\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 02] Loss: 0.5943 | Val Recall: 0.1111 | NDCG: 0.0599\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 03] Loss: 0.5369 | Val Recall: 0.1186 | NDCG: 0.0639\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 04] Loss: 0.4911 | Val Recall: 0.1201 | NDCG: 0.0647\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 05] Loss: 0.4665 | Val Recall: 0.1216 | NDCG: 0.0656\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 06] Loss: 0.4447 | Val Recall: 0.1291 | NDCG: 0.0674\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 07] Loss: 0.4257 | Val Recall: 0.1336 | NDCG: 0.0687\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 08] Loss: 0.4162 | Val Recall: 0.1321 | NDCG: 0.0680\n",
      "[Epoch 09] Loss: 0.3974 | Val Recall: 0.1366 | NDCG: 0.0699\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 10] Loss: 0.3865 | Val Recall: 0.1381 | NDCG: 0.0702\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 11] Loss: 0.3791 | Val Recall: 0.1366 | NDCG: 0.0702\n",
      "[Epoch 12] Loss: 0.3625 | Val Recall: 0.1306 | NDCG: 0.0690\n",
      "[Epoch 13] Loss: 0.3545 | Val Recall: 0.1351 | NDCG: 0.0718\n",
      "[Epoch 14] Loss: 0.3403 | Val Recall: 0.1291 | NDCG: 0.0714\n",
      "[Epoch 15] Loss: 0.3315 | Val Recall: 0.1261 | NDCG: 0.0702\n",
      "[Epoch 16] Loss: 0.3219 | Val Recall: 0.1291 | NDCG: 0.0719\n",
      "[Epoch 17] Loss: 0.3100 | Val Recall: 0.1306 | NDCG: 0.0731\n",
      "[Epoch 18] Loss: 0.3004 | Val Recall: 0.1336 | NDCG: 0.0730\n",
      "[Epoch 19] Loss: 0.2904 | Val Recall: 0.1396 | NDCG: 0.0751\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 20] Loss: 0.2848 | Val Recall: 0.1381 | NDCG: 0.0740\n",
      "[Epoch 21] Loss: 0.2781 | Val Recall: 0.1336 | NDCG: 0.0727\n",
      "[Epoch 22] Loss: 0.2715 | Val Recall: 0.1336 | NDCG: 0.0723\n",
      "[Epoch 23] Loss: 0.2633 | Val Recall: 0.1291 | NDCG: 0.0711\n",
      "[Epoch 24] Loss: 0.2578 | Val Recall: 0.1291 | NDCG: 0.0711\n",
      "[Epoch 25] Loss: 0.2555 | Val Recall: 0.1351 | NDCG: 0.0727\n",
      "[Epoch 26] Loss: 0.2458 | Val Recall: 0.1351 | NDCG: 0.0737\n",
      "[Epoch 27] Loss: 0.2416 | Val Recall: 0.1351 | NDCG: 0.0733\n",
      "[Epoch 28] Loss: 0.2366 | Val Recall: 0.1351 | NDCG: 0.0730\n",
      "[Epoch 29] Loss: 0.2317 | Val Recall: 0.1336 | NDCG: 0.0725\n",
      "[Epoch 30] Loss: 0.2270 | Val Recall: 0.1321 | NDCG: 0.0721\n",
      "[Epoch 31] Loss: 0.2254 | Val Recall: 0.1351 | NDCG: 0.0733\n",
      "[Epoch 32] Loss: 0.2203 | Val Recall: 0.1366 | NDCG: 0.0733\n",
      "[Epoch 33] Loss: 0.2145 | Val Recall: 0.1336 | NDCG: 0.0721\n",
      "[Epoch 34] Loss: 0.2123 | Val Recall: 0.1321 | NDCG: 0.0712\n",
      "[Epoch 35] Loss: 0.2066 | Val Recall: 0.1306 | NDCG: 0.0711\n",
      "[Epoch 36] Loss: 0.2046 | Val Recall: 0.1306 | NDCG: 0.0724\n",
      "[Epoch 37] Loss: 0.2028 | Val Recall: 0.1291 | NDCG: 0.0716\n",
      "[Epoch 38] Loss: 0.1948 | Val Recall: 0.1291 | NDCG: 0.0718\n",
      "[Epoch 39] Loss: 0.1927 | Val Recall: 0.1306 | NDCG: 0.0723\n",
      "[Epoch 40] Loss: 0.1924 | Val Recall: 0.1261 | NDCG: 0.0711\n",
      "[Epoch 41] Loss: 0.1859 | Val Recall: 0.1261 | NDCG: 0.0708\n",
      "[Epoch 42] Loss: 0.1828 | Val Recall: 0.1261 | NDCG: 0.0709\n",
      "[Epoch 43] Loss: 0.1824 | Val Recall: 0.1246 | NDCG: 0.0704\n",
      "[Epoch 44] Loss: 0.1797 | Val Recall: 0.1246 | NDCG: 0.0705\n",
      "[Epoch 45] Loss: 0.1741 | Val Recall: 0.1201 | NDCG: 0.0685\n",
      "[Epoch 46] Loss: 0.1727 | Val Recall: 0.1201 | NDCG: 0.0692\n",
      "[Epoch 47] Loss: 0.1691 | Val Recall: 0.1201 | NDCG: 0.0682\n",
      "[Epoch 48] Loss: 0.1683 | Val Recall: 0.1201 | NDCG: 0.0682\n",
      "[Epoch 49] Loss: 0.1652 | Val Recall: 0.1201 | NDCG: 0.0677\n",
      "[Epoch 50] Loss: 0.1655 | Val Recall: 0.1201 | NDCG: 0.0678\n",
      "\n",
      "=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: 19, Best Val Recall: 0.1396 ===\n",
      "\n",
      "=== Final Test Result (Best Model) ===\n",
      "Hit: 0.1486, Prec: 0.0149, Recall: 0.1486, NDCG: 0.0790\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Lamda2 = 1e-2 -> (0.01)\uc778 \uacbd\uc6b0**"
   ],
   "metadata": {
    "id": "S-2yd7n_Tl40"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "# 2. \ub370\uc774\ud130 \ub85c\ub4dc (Pre-split Data \uc0ac\uc6a9)\n",
    "# =========================================================\n",
    "if not os.path.exists(data_path) or not os.path.exists(movie_final_path):\n",
    "    print(\"Error: \ub370\uc774\ud130 \uacbd\ub85c\ub97c \ud655\uc778\ud574\uc8fc\uc138\uc694.\")\n",
    "else:\n",
    "    # 1. \ub370\uc774\ud130 \uc77d\uae30\n",
    "    train_df = pd.read_csv(f\"{data_path}/train.csv\")\n",
    "    val_df   = pd.read_csv(f\"{data_path}/val.csv\")\n",
    "    test_df  = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "    # 2. \ub9e4\ud551 \uc815\ubcf4 \ub85c\ub4dc\n",
    "    with open(f\"{data_path}/user2idx.pkl\", 'rb') as f: user2idx = pickle.load(f)\n",
    "    with open(f\"{data_path}/item2idx.pkl\", 'rb') as f: item2idx = pickle.load(f)\n",
    "\n",
    "    n_users = len(user2idx)\n",
    "    n_items = len(item2idx)\n",
    "\n",
    "    print(f\"\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: {n_users}, Item: {n_items}\")\n",
    "    print(f\"\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: {len(train_df)}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 3. \ub370\uc774\ud130 \ubd84\ub9ac (Positive vs Hard Negative)\n",
    "    # =========================================================\n",
    "    # 1) Positive Data (4\uc810 \uc774\uc0c1): \uadf8\ub798\ud504 \uc5f0\uacb0 \ubc0f \uc815\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_pos_df = train_df[train_df['rating'] >= 4.0].copy()\n",
    "\n",
    "    # 2) Hard Negative Data (2\uc810 \uc774\ud558): \uc624\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_neg_df = train_df[train_df['rating'] <= 2.0].copy()\n",
    "\n",
    "    print(f\"Positive Interactions (Graph\uc6a9): {len(train_pos_df)}\")\n",
    "    print(f\"Hard Negative Interactions: {len(train_neg_df)}\")\n",
    "\n",
    "    # \ub515\uc154\ub108\ub9ac \uc0dd\uc131\n",
    "    # Positive: \uc720\uc800\uac00 \uc88b\uc544\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d\n",
    "    user_pos_items = train_pos_df.groupby(\"user\")[\"item\"].apply(set).to_dict()\n",
    "\n",
    "    # Hard Negative: \uc720\uc800\uac00 \uc2eb\uc5b4\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d (\uc0d8\ud50c\ub9c1 \ub54c \uc0ac\uc6a9)\n",
    "    user_hard_neg_items = train_neg_df.groupby(\"user\")[\"item\"].apply(list).to_dict()\n",
    "\n",
    "    # =========================================================\n",
    "    # 4. Doc2Vec \ud559\uc2b5 \ubc0f \ub9e4\ud2b8\ub9ad\uc2a4 \uc0dd\uc131 (Feature Extraction)\n",
    "    # =========================================================\n",
    "    print(\"\\n=== Doc2Vec Training ===\")\n",
    "    movie_df = pd.read_csv(movie_final_path)\n",
    "    movie_df['overview_clean'] = movie_df['overview_clean'].fillna('unknown')\n",
    "\n",
    "    # TaggedDocument \uc0dd\uc131 (ID\ub294 \uc6d0\ubcf8 movieId \uc0ac\uc6a9 -> \ub098\uc911\uc5d0 item2idx\ub85c \ub9e4\ud551)\n",
    "    documents = [TaggedDocument(str(row['overview_clean']).split(), [str(row['movieId'])])\n",
    "                 for _, row in movie_df.iterrows()]\n",
    "\n",
    "    # LightGCN \ucc28\uc6d0(64)\uacfc \uc77c\uce58\uc2dc\ud0b4\n",
    "    d2v_model = Doc2Vec(documents, vector_size=64, window=5, min_count=1, workers=4, epochs=20, seed=42)\n",
    "\n",
    "    # Embedding Matrix \uc0dd\uc131 (item_idx \uc21c\uc11c\uc5d0 \ub9de\uac8c \uc815\ub82c)\n",
    "    doc2vec_weights = np.zeros((n_items, 64))\n",
    "    cnt = 0\n",
    "    for movie_id, idx in item2idx.items():\n",
    "        # Doc2Vec \ubaa8\ub378\uc5d0 \ud574\ub2f9 \uc601\ud654 ID\uac00 \uc788\ub294\uc9c0 \ud655\uc778\n",
    "        if str(movie_id) in d2v_model.dv:\n",
    "            doc2vec_weights[idx] = d2v_model.dv[str(movie_id)]\n",
    "            cnt += 1\n",
    "        else:\n",
    "            # \uc5c6\uc73c\uba74 \ub79c\ub364 \ucd08\uae30\ud654 (\uc791\uc740 \uac12)\n",
    "            doc2vec_weights[idx] = np.random.normal(0, 0.01, 64)\n",
    "\n",
    "    doc2vec_weights = torch.FloatTensor(doc2vec_weights).to(device)\n",
    "    print(f\"Doc2Vec Matrix Created. Mapped: {cnt}/{n_items}\")\n",
    "\n",
    "\n",
    "    # Save Doc2Vec embeddings to disk for reuse\n",
    "    doc2vec_save_path = f\"{base_path}/doc2vec_embeddings_64d.pkl\"\n",
    "    with open(doc2vec_save_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'embeddings': doc2vec_weights.cpu().numpy(),\n",
    "            'item2idx': item2idx,\n",
    "            'n_items': n_items,\n",
    "            'vector_size': 64,\n",
    "            'created_at': str(pd.Timestamp.now())\n",
    "        }, f)\n",
    "    print(f\"\u2705 Doc2Vec embeddings saved to: {doc2vec_save_path}\")\n",
    "    # =========================================================\n",
    "    # 5. LightGCN\uc6a9 \uc778\uc811\ud589\ub82c \uc0dd\uc131 (Positive \ub370\uc774\ud130\ub9cc \uc0ac\uc6a9!)\n",
    "    # =========================================================\n",
    "    def get_adj_mat(n_users, n_items, pos_df):\n",
    "        \"\"\"\n",
    "        \ubc18\ub4dc\uc2dc 4\uc810 \uc774\uc0c1\uc778 pos_df\ub9cc \ub123\uc5b4\uc11c \uadf8\ub798\ud504\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud568\n",
    "        \"\"\"\n",
    "        n_nodes = n_users + n_items\n",
    "        user_np = pos_df['user'].values\n",
    "        item_np = pos_df['item'].values\n",
    "\n",
    "        R = sp.coo_matrix((np.ones(len(user_np)), (user_np, item_np)), shape=(n_users, n_items))\n",
    "\n",
    "        top_part = sp.hstack([sp.csr_matrix((n_users, n_users)), R])\n",
    "        bot_part = sp.hstack([R.T, sp.csr_matrix((n_items, n_items))])\n",
    "        A = sp.vstack([top_part, bot_part])\n",
    "\n",
    "        rowsum = np.array(A.sum(1))\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "\n",
    "        norm_adj = d_mat_inv_sqrt.dot(A).dot(d_mat_inv_sqrt).tocoo()\n",
    "        indices = torch.LongTensor(np.vstack((norm_adj.row, norm_adj.col)))\n",
    "        values = torch.FloatTensor(norm_adj.data)\n",
    "\n",
    "        return torch.sparse_coo_tensor(indices, values, torch.Size(norm_adj.shape)).to(device)\n",
    "\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\")\n",
    "    Adj_Matrix = get_adj_mat(n_users, n_items, train_pos_df)\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 6. \ubaa8\ub378 \uc815\uc758 (LightGCN with Doc2Vec Init)\n",
    "    # =========================================================\n",
    "    class LightGCN_Doc2Vec(nn.Module):\n",
    "        def __init__(self, n_users, n_items, dim, layers, A_hat, doc2vec_weights):\n",
    "            super().__init__()\n",
    "            self.n_users = n_users\n",
    "            self.n_items = n_items\n",
    "            self.dim = dim\n",
    "            self.layers = layers\n",
    "            self.A_hat = A_hat\n",
    "\n",
    "            # User\ub294 \ub79c\ub364 \ucd08\uae30\ud654\n",
    "            self.user_emb = nn.Embedding(n_users, dim)\n",
    "            nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "\n",
    "            # [\ud575\uc2ec] Item\uc740 Doc2Vec\uc73c\ub85c \ucd08\uae30\ud654 (freeze=False: \ud559\uc2b5 \uac00\ub2a5)\n",
    "            self.item_emb = nn.Embedding.from_pretrained(doc2vec_weights, freeze=False)\n",
    "\n",
    "            # Content Loss \uacc4\uc0b0\uc6a9 \uace0\uc815 \ubca1\ud130 (Buffer) - \ud559\uc2b5 \uc548 \ub428\n",
    "            self.register_buffer('fixed_doc2vec', doc2vec_weights.clone().detach())\n",
    "\n",
    "        def get_all_embeddings(self):\n",
    "            users = self.user_emb.weight\n",
    "            items = self.item_emb.weight\n",
    "            all_emb = torch.cat([users, items], dim=0)\n",
    "\n",
    "            embs = [all_emb]\n",
    "            for _ in range(self.layers):\n",
    "                all_emb = torch.sparse.mm(self.A_hat, all_emb)\n",
    "                embs.append(all_emb)\n",
    "\n",
    "            out = torch.stack(embs, dim=0).mean(dim=0)\n",
    "            return out[:self.n_users], out[self.n_users:]\n",
    "\n",
    "    # =========================================================\n",
    "    # 7. Loss & Sampling (Hard Negative + Content Loss)\n",
    "    # =========================================================\n",
    "    def sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5):\n",
    "        users = np.random.choice(list(user_pos_items.keys()), size=batch_size)\n",
    "        pos = []\n",
    "        neg = []\n",
    "\n",
    "        for u in users:\n",
    "            # Positive Sampling\n",
    "            pos.append(np.random.choice(list(user_pos_items[u])))\n",
    "\n",
    "            # Hard Negative Sampling (50% \ud655\ub960)\n",
    "            if (u in user_hard_neg_items) and (len(user_hard_neg_items[u]) > 0) and (random.random() < hard_prob):\n",
    "                neg.append(np.random.choice(user_hard_neg_items[u]))\n",
    "            else:\n",
    "                # Random Negative\n",
    "                while True:\n",
    "                    n = np.random.randint(0, n_items)\n",
    "                    if n not in user_pos_items[u]:\n",
    "                        neg.append(n); break\n",
    "\n",
    "        return (torch.LongTensor(users).to(device),\n",
    "                torch.LongTensor(pos).to(device),\n",
    "                torch.LongTensor(neg).to(device))\n",
    "\n",
    "    def bpr_loss_with_content(u_f, i_pos_f, i_neg_f, u_0, i_pos_0, i_neg_0, fixed_vec, lambda1, lambda2):\n",
    "        \"\"\"\n",
    "        u_f, i_pos_f, i_neg_f : \uc804\ud30c\ub41c \uc784\ubca0\ub529 (BPR\uc6a9)\n",
    "        u_0, i_pos_0, i_neg_0 : \ucd08\uae30 \uc784\ubca0\ub529 (Regularization\uc6a9)\n",
    "        fixed_vec             : \uace0\uc815\ub41c Doc2Vec \ubca1\ud130 (Content Loss\uc6a9)\n",
    "        \"\"\"\n",
    "        # 1. BPR Loss\n",
    "        pos_scores = (u_f * i_pos_f).sum(dim=1)\n",
    "        neg_scores = (u_f * i_neg_f).sum(dim=1)\n",
    "        bpr_loss = torch.mean(torch.nn.functional.softplus(-(pos_scores - neg_scores)))\n",
    "\n",
    "        # 2. L2 Regularization (E^0 \uae30\uc900)\n",
    "        reg_loss = 0.5 * (u_0.norm(2).pow(2) + i_pos_0.norm(2).pow(2) + i_neg_0.norm(2).pow(2)) / u_0.size(0)\n",
    "\n",
    "        # 3. Content Loss (E^0 vs Fixed Doc2Vec)\n",
    "        content_loss = F.mse_loss(i_pos_0, fixed_vec)\n",
    "\n",
    "        return bpr_loss + lambda1 * reg_loss + lambda2 * content_loss\n",
    "\n",
    "    # =========================================================\n",
    "    # 8. \ud3c9\uac00 \ud568\uc218 (Precision, Recall, NDCG, HitRate)\n",
    "    # =========================================================\n",
    "    def ndcg_at_k(rank, k):\n",
    "        if rank is None or rank >= k: return 0.0\n",
    "        return 1.0 / math.log2(rank + 2)\n",
    "\n",
    "    def evaluate(model, df_eval, k=10):\n",
    "        model.eval()\n",
    "        users_final, items_final = model.get_all_embeddings()\n",
    "        hits, ndcg, precision, recall, total_users = 0, 0, 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for u_idx, group in df_eval.groupby('user'):\n",
    "                total_users += 1\n",
    "                target_items = set(group['item'].values)\n",
    "\n",
    "                scores = torch.matmul(users_final[u_idx], items_final.t())\n",
    "\n",
    "                # Train\uc5d0\uc11c \ubcf8 \uc544\uc774\ud15c(Positive Only)\uc740 \ub9c8\uc2a4\ud0b9\n",
    "                if u_idx in user_pos_items:\n",
    "                    scores[list(user_pos_items[u_idx])] = -1e9\n",
    "\n",
    "                _, topk = torch.topk(scores, k)\n",
    "                topk = topk.cpu().tolist()\n",
    "\n",
    "                num_correct = 0\n",
    "                dcg, idcg = 0.0, 0.0\n",
    "\n",
    "                for i, item_id in enumerate(topk):\n",
    "                    if item_id in target_items:\n",
    "                        num_correct += 1\n",
    "                        dcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                num_targets = len(target_items)\n",
    "                for i in range(min(num_targets, k)):\n",
    "                    idcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                if num_correct > 0: hits += 1\n",
    "                precision += num_correct / k\n",
    "                recall += num_correct / num_targets\n",
    "                if idcg > 0: ndcg += dcg / idcg\n",
    "\n",
    "        return {'HitRate': hits/total_users, 'Precision': precision/total_users, 'Recall': recall/total_users, 'NDCG': ndcg/total_users}\n",
    "\n",
    "    # =========================================================\n",
    "    # 9. \ud559\uc2b5 \uc2e4\ud589 (Best Model Selection \uc801\uc6a9)\n",
    "    # =========================================================\n",
    "    dim = 64\n",
    "    layers = 3\n",
    "    batch_size = 1024\n",
    "    epochs = 25\n",
    "    lr = 1e-3\n",
    "\n",
    "    # [\uc124\uc815] \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\n",
    "    lambda1 = 1e-5  # Reg (Base \uc2e4\ud5d8 \uacb0\uacfc \ubc18\uc601)\n",
    "    lambda2 = 1e-2  # Content Loss (Doc2Vec Init\ub9cc \uc4f0\ub824\uba74 0, \uaddc\uc81c\ud558\ub824\uba74 1e-3 \ub4f1)\n",
    "\n",
    "    model = LightGCN_Doc2Vec(n_users, n_items, dim, layers, Adj_Matrix, doc2vec_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Best Model \uc800\uc7a5 \ubcc0\uc218\n",
    "    best_recall = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_path = \"best_doc2vec_lightgcn.pt\"\n",
    "\n",
    "    print(f\"\\n=== Training Start (Lambda2={lambda2}, Hard Negative Applied) ===\")\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # \ubc30\uce58 \uc218\ub294 Positive Data \uae30\uc900\n",
    "        num_batches = len(train_pos_df) // batch_size + 1\n",
    "\n",
    "        for _ in range(num_batches):\n",
    "            # 1. \uc0d8\ud50c\ub9c1 (Hard Negative \ud3ec\ud568)\n",
    "            users, pos, neg = sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5)\n",
    "\n",
    "            # 2. \uc804\ud30c (BPR \uc6a9)\n",
    "            u_final, i_final = model.get_all_embeddings()\n",
    "            u_f = u_final[users]\n",
    "            i_pos_f = i_final[pos]\n",
    "            i_neg_f = i_final[neg]\n",
    "\n",
    "            # 3. \ucd08\uae30\uac12 (Reg & Content \uc6a9)\n",
    "            u_0 = model.user_emb.weight[users]\n",
    "            i_pos_0 = model.item_emb.weight[pos]\n",
    "            i_neg_0 = model.item_emb.weight[neg]\n",
    "\n",
    "            # 4. \uace0\uc815\ub41c Doc2Vec \ucd94\ucd9c\n",
    "            fixed_vec = model.fixed_doc2vec[pos]\n",
    "\n",
    "            # 5. Loss \uacc4\uc0b0\n",
    "            loss = bpr_loss_with_content(u_f, i_pos_f, i_neg_f,\n",
    "                                         u_0, i_pos_0, i_neg_0,\n",
    "                                         fixed_vec, lambda1, lambda2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # \ub9e4 Epoch\ub9c8\ub2e4 Validation \ud3c9\uac00\n",
    "        val_metrics = evaluate(model, val_df, k=10)\n",
    "        current_recall = val_metrics['Recall']\n",
    "\n",
    "        print(f\"[Epoch {epoch:02d}] Loss: {total_loss/num_batches:.4f} | Val Recall: {current_recall:.4f} | NDCG: {val_metrics['NDCG']:.4f}\")\n",
    "\n",
    "        if current_recall > best_recall:\n",
    "            best_recall = current_recall\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"   >>> Best Model Updated!\")\n",
    "\n",
    "    print(f\"\\n=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: {best_epoch}, Best Val Recall: {best_recall:.4f} ===\")\n",
    "\n",
    "    # Final Test with Best Model\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    test_metrics = evaluate(model, test_df, k=10)\n",
    "    print(\"\\n=== Final Test Result (Best Model) ===\")\n",
    "    print(f\"Hit: {test_metrics['HitRate']:.4f}, Prec: {test_metrics['Precision']:.4f}, Recall: {test_metrics['Recall']:.4f}, NDCG: {test_metrics['NDCG']:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LPzLIXV7Twsf",
    "outputId": "7689912f-953d-43e8-a500-5ba913117c7a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: 671, Item: 3485\n",
      "\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: 88595\n",
      "Positive Interactions (Graph\uc6a9): 46243\n",
      "Hard Negative Interactions: 11327\n",
      "\n",
      "=== Doc2Vec Training ===\n",
      "Doc2Vec Matrix Created. Mapped: 3485/3485\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\n",
      "\n",
      "=== Training Start (Lambda2=0.01, Hard Negative Applied) ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-2509660017.py:88: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch 01] Loss: 0.6469 | Val Recall: 0.0991 | NDCG: 0.0544\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 02] Loss: 0.5967 | Val Recall: 0.1156 | NDCG: 0.0600\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 03] Loss: 0.5375 | Val Recall: 0.1186 | NDCG: 0.0629\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 04] Loss: 0.4926 | Val Recall: 0.1231 | NDCG: 0.0648\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 05] Loss: 0.4666 | Val Recall: 0.1276 | NDCG: 0.0674\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 06] Loss: 0.4460 | Val Recall: 0.1306 | NDCG: 0.0682\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 07] Loss: 0.4295 | Val Recall: 0.1336 | NDCG: 0.0688\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 08] Loss: 0.4180 | Val Recall: 0.1351 | NDCG: 0.0691\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 09] Loss: 0.4000 | Val Recall: 0.1366 | NDCG: 0.0697\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 10] Loss: 0.3931 | Val Recall: 0.1411 | NDCG: 0.0726\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 11] Loss: 0.3746 | Val Recall: 0.1411 | NDCG: 0.0722\n",
      "[Epoch 12] Loss: 0.3641 | Val Recall: 0.1336 | NDCG: 0.0711\n",
      "[Epoch 13] Loss: 0.3488 | Val Recall: 0.1336 | NDCG: 0.0728\n",
      "[Epoch 14] Loss: 0.3382 | Val Recall: 0.1426 | NDCG: 0.0764\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 15] Loss: 0.3296 | Val Recall: 0.1426 | NDCG: 0.0780\n",
      "[Epoch 16] Loss: 0.3169 | Val Recall: 0.1471 | NDCG: 0.0802\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 17] Loss: 0.3071 | Val Recall: 0.1441 | NDCG: 0.0802\n",
      "[Epoch 18] Loss: 0.2956 | Val Recall: 0.1426 | NDCG: 0.0798\n",
      "[Epoch 19] Loss: 0.2927 | Val Recall: 0.1441 | NDCG: 0.0791\n",
      "[Epoch 20] Loss: 0.2778 | Val Recall: 0.1411 | NDCG: 0.0787\n",
      "[Epoch 21] Loss: 0.2722 | Val Recall: 0.1426 | NDCG: 0.0783\n",
      "[Epoch 22] Loss: 0.2676 | Val Recall: 0.1411 | NDCG: 0.0774\n",
      "[Epoch 23] Loss: 0.2600 | Val Recall: 0.1396 | NDCG: 0.0772\n",
      "[Epoch 24] Loss: 0.2496 | Val Recall: 0.1396 | NDCG: 0.0771\n",
      "[Epoch 25] Loss: 0.2488 | Val Recall: 0.1426 | NDCG: 0.0774\n",
      "\n",
      "=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: 16, Best Val Recall: 0.1471 ===\n",
      "\n",
      "=== Final Test Result (Best Model) ===\n",
      "Hit: 0.1532, Prec: 0.0153, Recall: 0.1532, NDCG: 0.0806\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Lamda2 = 1e-3 -> (0.001)\uc778 \uacbd\uc6b0**"
   ],
   "metadata": {
    "id": "GMFxS97uWElE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "# 2. \ub370\uc774\ud130 \ub85c\ub4dc (Pre-split Data \uc0ac\uc6a9)\n",
    "# =========================================================\n",
    "if not os.path.exists(data_path) or not os.path.exists(movie_final_path):\n",
    "    print(\"Error: \ub370\uc774\ud130 \uacbd\ub85c\ub97c \ud655\uc778\ud574\uc8fc\uc138\uc694.\")\n",
    "else:\n",
    "    # 1. \ub370\uc774\ud130 \uc77d\uae30\n",
    "    train_df = pd.read_csv(f\"{data_path}/train.csv\")\n",
    "    val_df   = pd.read_csv(f\"{data_path}/val.csv\")\n",
    "    test_df  = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "    # 2. \ub9e4\ud551 \uc815\ubcf4 \ub85c\ub4dc\n",
    "    with open(f\"{data_path}/user2idx.pkl\", 'rb') as f: user2idx = pickle.load(f)\n",
    "    with open(f\"{data_path}/item2idx.pkl\", 'rb') as f: item2idx = pickle.load(f)\n",
    "\n",
    "    n_users = len(user2idx)\n",
    "    n_items = len(item2idx)\n",
    "\n",
    "    print(f\"\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: {n_users}, Item: {n_items}\")\n",
    "    print(f\"\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: {len(train_df)}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 3. \ub370\uc774\ud130 \ubd84\ub9ac (Positive vs Hard Negative)\n",
    "    # =========================================================\n",
    "    # 1) Positive Data (4\uc810 \uc774\uc0c1): \uadf8\ub798\ud504 \uc5f0\uacb0 \ubc0f \uc815\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_pos_df = train_df[train_df['rating'] >= 4.0].copy()\n",
    "\n",
    "    # 2) Hard Negative Data (2\uc810 \uc774\ud558): \uc624\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_neg_df = train_df[train_df['rating'] <= 2.0].copy()\n",
    "\n",
    "    print(f\"Positive Interactions (Graph\uc6a9): {len(train_pos_df)}\")\n",
    "    print(f\"Hard Negative Interactions: {len(train_neg_df)}\")\n",
    "\n",
    "    # \ub515\uc154\ub108\ub9ac \uc0dd\uc131\n",
    "    # Positive: \uc720\uc800\uac00 \uc88b\uc544\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d\n",
    "    user_pos_items = train_pos_df.groupby(\"user\")[\"item\"].apply(set).to_dict()\n",
    "\n",
    "    # Hard Negative: \uc720\uc800\uac00 \uc2eb\uc5b4\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d (\uc0d8\ud50c\ub9c1 \ub54c \uc0ac\uc6a9)\n",
    "    user_hard_neg_items = train_neg_df.groupby(\"user\")[\"item\"].apply(list).to_dict()\n",
    "\n",
    "    # =========================================================\n",
    "    # 4. Doc2Vec \ud559\uc2b5 \ubc0f \ub9e4\ud2b8\ub9ad\uc2a4 \uc0dd\uc131 (Feature Extraction)\n",
    "    # =========================================================\n",
    "    print(\"\\n=== Doc2Vec Training ===\")\n",
    "    movie_df = pd.read_csv(movie_final_path)\n",
    "    movie_df['overview_clean'] = movie_df['overview_clean'].fillna('unknown')\n",
    "\n",
    "    # TaggedDocument \uc0dd\uc131 (ID\ub294 \uc6d0\ubcf8 movieId \uc0ac\uc6a9 -> \ub098\uc911\uc5d0 item2idx\ub85c \ub9e4\ud551)\n",
    "    documents = [TaggedDocument(str(row['overview_clean']).split(), [str(row['movieId'])])\n",
    "                 for _, row in movie_df.iterrows()]\n",
    "\n",
    "    # LightGCN \ucc28\uc6d0(64)\uacfc \uc77c\uce58\uc2dc\ud0b4\n",
    "    d2v_model = Doc2Vec(documents, vector_size=64, window=5, min_count=1, workers=4, epochs=20, seed=42)\n",
    "\n",
    "    # Embedding Matrix \uc0dd\uc131 (item_idx \uc21c\uc11c\uc5d0 \ub9de\uac8c \uc815\ub82c)\n",
    "    doc2vec_weights = np.zeros((n_items, 64))\n",
    "    cnt = 0\n",
    "    for movie_id, idx in item2idx.items():\n",
    "        # Doc2Vec \ubaa8\ub378\uc5d0 \ud574\ub2f9 \uc601\ud654 ID\uac00 \uc788\ub294\uc9c0 \ud655\uc778\n",
    "        if str(movie_id) in d2v_model.dv:\n",
    "            doc2vec_weights[idx] = d2v_model.dv[str(movie_id)]\n",
    "            cnt += 1\n",
    "        else:\n",
    "            # \uc5c6\uc73c\uba74 \ub79c\ub364 \ucd08\uae30\ud654 (\uc791\uc740 \uac12)\n",
    "            doc2vec_weights[idx] = np.random.normal(0, 0.01, 64)\n",
    "\n",
    "    doc2vec_weights = torch.FloatTensor(doc2vec_weights).to(device)\n",
    "    print(f\"Doc2Vec Matrix Created. Mapped: {cnt}/{n_items}\")\n",
    "\n",
    "\n",
    "    # Save Doc2Vec embeddings to disk for reuse\n",
    "    doc2vec_save_path = f\"{base_path}/doc2vec_embeddings_64d.pkl\"\n",
    "    with open(doc2vec_save_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'embeddings': doc2vec_weights.cpu().numpy(),\n",
    "            'item2idx': item2idx,\n",
    "            'n_items': n_items,\n",
    "            'vector_size': 64,\n",
    "            'created_at': str(pd.Timestamp.now())\n",
    "        }, f)\n",
    "    print(f\"\u2705 Doc2Vec embeddings saved to: {doc2vec_save_path}\")\n",
    "    # =========================================================\n",
    "    # 5. LightGCN\uc6a9 \uc778\uc811\ud589\ub82c \uc0dd\uc131 (Positive \ub370\uc774\ud130\ub9cc \uc0ac\uc6a9!)\n",
    "    # =========================================================\n",
    "    def get_adj_mat(n_users, n_items, pos_df):\n",
    "        \"\"\"\n",
    "        \ubc18\ub4dc\uc2dc 4\uc810 \uc774\uc0c1\uc778 pos_df\ub9cc \ub123\uc5b4\uc11c \uadf8\ub798\ud504\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud568\n",
    "        \"\"\"\n",
    "        n_nodes = n_users + n_items\n",
    "        user_np = pos_df['user'].values\n",
    "        item_np = pos_df['item'].values\n",
    "\n",
    "        R = sp.coo_matrix((np.ones(len(user_np)), (user_np, item_np)), shape=(n_users, n_items))\n",
    "\n",
    "        top_part = sp.hstack([sp.csr_matrix((n_users, n_users)), R])\n",
    "        bot_part = sp.hstack([R.T, sp.csr_matrix((n_items, n_items))])\n",
    "        A = sp.vstack([top_part, bot_part])\n",
    "\n",
    "        rowsum = np.array(A.sum(1))\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "\n",
    "        norm_adj = d_mat_inv_sqrt.dot(A).dot(d_mat_inv_sqrt).tocoo()\n",
    "        indices = torch.LongTensor(np.vstack((norm_adj.row, norm_adj.col)))\n",
    "        values = torch.FloatTensor(norm_adj.data)\n",
    "\n",
    "        return torch.sparse_coo_tensor(indices, values, torch.Size(norm_adj.shape)).to(device)\n",
    "\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\")\n",
    "    Adj_Matrix = get_adj_mat(n_users, n_items, train_pos_df)\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 6. \ubaa8\ub378 \uc815\uc758 (LightGCN with Doc2Vec Init)\n",
    "    # =========================================================\n",
    "    class LightGCN_Doc2Vec(nn.Module):\n",
    "        def __init__(self, n_users, n_items, dim, layers, A_hat, doc2vec_weights):\n",
    "            super().__init__()\n",
    "            self.n_users = n_users\n",
    "            self.n_items = n_items\n",
    "            self.dim = dim\n",
    "            self.layers = layers\n",
    "            self.A_hat = A_hat\n",
    "\n",
    "            # User\ub294 \ub79c\ub364 \ucd08\uae30\ud654\n",
    "            self.user_emb = nn.Embedding(n_users, dim)\n",
    "            nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "\n",
    "            # [\ud575\uc2ec] Item\uc740 Doc2Vec\uc73c\ub85c \ucd08\uae30\ud654 (freeze=False: \ud559\uc2b5 \uac00\ub2a5)\n",
    "            self.item_emb = nn.Embedding.from_pretrained(doc2vec_weights, freeze=False)\n",
    "\n",
    "            # Content Loss \uacc4\uc0b0\uc6a9 \uace0\uc815 \ubca1\ud130 (Buffer) - \ud559\uc2b5 \uc548 \ub428\n",
    "            self.register_buffer('fixed_doc2vec', doc2vec_weights.clone().detach())\n",
    "\n",
    "        def get_all_embeddings(self):\n",
    "            users = self.user_emb.weight\n",
    "            items = self.item_emb.weight\n",
    "            all_emb = torch.cat([users, items], dim=0)\n",
    "\n",
    "            embs = [all_emb]\n",
    "            for _ in range(self.layers):\n",
    "                all_emb = torch.sparse.mm(self.A_hat, all_emb)\n",
    "                embs.append(all_emb)\n",
    "\n",
    "            out = torch.stack(embs, dim=0).mean(dim=0)\n",
    "            return out[:self.n_users], out[self.n_users:]\n",
    "\n",
    "    # =========================================================\n",
    "    # 7. Loss & Sampling (Hard Negative + Content Loss)\n",
    "    # =========================================================\n",
    "    def sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5):\n",
    "        users = np.random.choice(list(user_pos_items.keys()), size=batch_size)\n",
    "        pos = []\n",
    "        neg = []\n",
    "\n",
    "        for u in users:\n",
    "            # Positive Sampling\n",
    "            pos.append(np.random.choice(list(user_pos_items[u])))\n",
    "\n",
    "            # Hard Negative Sampling (50% \ud655\ub960)\n",
    "            if (u in user_hard_neg_items) and (len(user_hard_neg_items[u]) > 0) and (random.random() < hard_prob):\n",
    "                neg.append(np.random.choice(user_hard_neg_items[u]))\n",
    "            else:\n",
    "                # Random Negative\n",
    "                while True:\n",
    "                    n = np.random.randint(0, n_items)\n",
    "                    if n not in user_pos_items[u]:\n",
    "                        neg.append(n); break\n",
    "\n",
    "        return (torch.LongTensor(users).to(device),\n",
    "                torch.LongTensor(pos).to(device),\n",
    "                torch.LongTensor(neg).to(device))\n",
    "\n",
    "    def bpr_loss_with_content(u_f, i_pos_f, i_neg_f, u_0, i_pos_0, i_neg_0, fixed_vec, lambda1, lambda2):\n",
    "        \"\"\"\n",
    "        u_f, i_pos_f, i_neg_f : \uc804\ud30c\ub41c \uc784\ubca0\ub529 (BPR\uc6a9)\n",
    "        u_0, i_pos_0, i_neg_0 : \ucd08\uae30 \uc784\ubca0\ub529 (Regularization\uc6a9)\n",
    "        fixed_vec             : \uace0\uc815\ub41c Doc2Vec \ubca1\ud130 (Content Loss\uc6a9)\n",
    "        \"\"\"\n",
    "        # 1. BPR Loss\n",
    "        pos_scores = (u_f * i_pos_f).sum(dim=1)\n",
    "        neg_scores = (u_f * i_neg_f).sum(dim=1)\n",
    "        bpr_loss = torch.mean(torch.nn.functional.softplus(-(pos_scores - neg_scores)))\n",
    "\n",
    "        # 2. L2 Regularization (E^0 \uae30\uc900)\n",
    "        reg_loss = 0.5 * (u_0.norm(2).pow(2) + i_pos_0.norm(2).pow(2) + i_neg_0.norm(2).pow(2)) / u_0.size(0)\n",
    "\n",
    "        # 3. Content Loss (E^0 vs Fixed Doc2Vec)\n",
    "        content_loss = F.mse_loss(i_pos_0, fixed_vec)\n",
    "\n",
    "        return bpr_loss + lambda1 * reg_loss + lambda2 * content_loss\n",
    "\n",
    "    # =========================================================\n",
    "    # 8. \ud3c9\uac00 \ud568\uc218 (Precision, Recall, NDCG, HitRate)\n",
    "    # =========================================================\n",
    "    def ndcg_at_k(rank, k):\n",
    "        if rank is None or rank >= k: return 0.0\n",
    "        return 1.0 / math.log2(rank + 2)\n",
    "\n",
    "    def evaluate(model, df_eval, k=10):\n",
    "        model.eval()\n",
    "        users_final, items_final = model.get_all_embeddings()\n",
    "        hits, ndcg, precision, recall, total_users = 0, 0, 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for u_idx, group in df_eval.groupby('user'):\n",
    "                total_users += 1\n",
    "                target_items = set(group['item'].values)\n",
    "\n",
    "                scores = torch.matmul(users_final[u_idx], items_final.t())\n",
    "\n",
    "                # Train\uc5d0\uc11c \ubcf8 \uc544\uc774\ud15c(Positive Only)\uc740 \ub9c8\uc2a4\ud0b9\n",
    "                if u_idx in user_pos_items:\n",
    "                    scores[list(user_pos_items[u_idx])] = -1e9\n",
    "\n",
    "                _, topk = torch.topk(scores, k)\n",
    "                topk = topk.cpu().tolist()\n",
    "\n",
    "                num_correct = 0\n",
    "                dcg, idcg = 0.0, 0.0\n",
    "\n",
    "                for i, item_id in enumerate(topk):\n",
    "                    if item_id in target_items:\n",
    "                        num_correct += 1\n",
    "                        dcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                num_targets = len(target_items)\n",
    "                for i in range(min(num_targets, k)):\n",
    "                    idcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                if num_correct > 0: hits += 1\n",
    "                precision += num_correct / k\n",
    "                recall += num_correct / num_targets\n",
    "                if idcg > 0: ndcg += dcg / idcg\n",
    "\n",
    "        return {'HitRate': hits/total_users, 'Precision': precision/total_users, 'Recall': recall/total_users, 'NDCG': ndcg/total_users}\n",
    "\n",
    "    # =========================================================\n",
    "    # 9. \ud559\uc2b5 \uc2e4\ud589 (Best Model Selection \uc801\uc6a9)\n",
    "    # =========================================================\n",
    "    dim = 64\n",
    "    layers = 3\n",
    "    batch_size = 1024\n",
    "    epochs = 25\n",
    "    lr = 1e-3\n",
    "\n",
    "    # [\uc124\uc815] \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\n",
    "    lambda1 = 1e-5  # Reg (Base \uc2e4\ud5d8 \uacb0\uacfc \ubc18\uc601)\n",
    "    lambda2 = 1e-3  # Content Loss (Doc2Vec Init\ub9cc \uc4f0\ub824\uba74 0, \uaddc\uc81c\ud558\ub824\uba74 1e-3 \ub4f1)\n",
    "\n",
    "    model = LightGCN_Doc2Vec(n_users, n_items, dim, layers, Adj_Matrix, doc2vec_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Best Model \uc800\uc7a5 \ubcc0\uc218\n",
    "    best_recall = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_path = \"best_doc2vec_lightgcn.pt\"\n",
    "\n",
    "    print(f\"\\n=== Training Start (Lambda2={lambda2}, Hard Negative Applied) ===\")\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # \ubc30\uce58 \uc218\ub294 Positive Data \uae30\uc900\n",
    "        num_batches = len(train_pos_df) // batch_size + 1\n",
    "\n",
    "        for _ in range(num_batches):\n",
    "            # 1. \uc0d8\ud50c\ub9c1 (Hard Negative \ud3ec\ud568)\n",
    "            users, pos, neg = sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5)\n",
    "\n",
    "            # 2. \uc804\ud30c (BPR \uc6a9)\n",
    "            u_final, i_final = model.get_all_embeddings()\n",
    "            u_f = u_final[users]\n",
    "            i_pos_f = i_final[pos]\n",
    "            i_neg_f = i_final[neg]\n",
    "\n",
    "            # 3. \ucd08\uae30\uac12 (Reg & Content \uc6a9)\n",
    "            u_0 = model.user_emb.weight[users]\n",
    "            i_pos_0 = model.item_emb.weight[pos]\n",
    "            i_neg_0 = model.item_emb.weight[neg]\n",
    "\n",
    "            # 4. \uace0\uc815\ub41c Doc2Vec \ucd94\ucd9c\n",
    "            fixed_vec = model.fixed_doc2vec[pos]\n",
    "\n",
    "            # 5. Loss \uacc4\uc0b0\n",
    "            loss = bpr_loss_with_content(u_f, i_pos_f, i_neg_f,\n",
    "                                         u_0, i_pos_0, i_neg_0,\n",
    "                                         fixed_vec, lambda1, lambda2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # \ub9e4 Epoch\ub9c8\ub2e4 Validation \ud3c9\uac00\n",
    "        val_metrics = evaluate(model, val_df, k=10)\n",
    "        current_recall = val_metrics['Recall']\n",
    "\n",
    "        print(f\"[Epoch {epoch:02d}] Loss: {total_loss/num_batches:.4f} | Val Recall: {current_recall:.4f} | NDCG: {val_metrics['NDCG']:.4f}\")\n",
    "\n",
    "        if current_recall > best_recall:\n",
    "            best_recall = current_recall\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"   >>> Best Model Updated!\")\n",
    "\n",
    "    print(f\"\\n=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: {best_epoch}, Best Val Recall: {best_recall:.4f} ===\")\n",
    "\n",
    "    # Final Test with Best Model\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    test_metrics = evaluate(model, test_df, k=10)\n",
    "    print(\"\\n=== Final Test Result (Best Model) ===\")\n",
    "    print(f\"Hit: {test_metrics['HitRate']:.4f}, Prec: {test_metrics['Precision']:.4f}, Recall: {test_metrics['Recall']:.4f}, NDCG: {test_metrics['NDCG']:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrzojVOAWAe6",
    "outputId": "19f83337-54e5-4b8a-ab24-11104b749a3d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: 671, Item: 3485\n",
      "\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: 88595\n",
      "Positive Interactions (Graph\uc6a9): 46243\n",
      "Hard Negative Interactions: 11327\n",
      "\n",
      "=== Doc2Vec Training ===\n",
      "Doc2Vec Matrix Created. Mapped: 3485/3485\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\n",
      "\n",
      "=== Training Start (Lambda2=0.001, Hard Negative Applied) ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-1983347284.py:88: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch 01] Loss: 0.6468 | Val Recall: 0.1066 | NDCG: 0.0567\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 02] Loss: 0.5923 | Val Recall: 0.1096 | NDCG: 0.0588\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 03] Loss: 0.5354 | Val Recall: 0.1186 | NDCG: 0.0636\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 04] Loss: 0.4913 | Val Recall: 0.1216 | NDCG: 0.0646\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 05] Loss: 0.4658 | Val Recall: 0.1246 | NDCG: 0.0654\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 06] Loss: 0.4458 | Val Recall: 0.1276 | NDCG: 0.0665\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 07] Loss: 0.4306 | Val Recall: 0.1336 | NDCG: 0.0681\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 08] Loss: 0.4191 | Val Recall: 0.1366 | NDCG: 0.0689\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 09] Loss: 0.4034 | Val Recall: 0.1351 | NDCG: 0.0683\n",
      "[Epoch 10] Loss: 0.3969 | Val Recall: 0.1366 | NDCG: 0.0689\n",
      "[Epoch 11] Loss: 0.3819 | Val Recall: 0.1396 | NDCG: 0.0699\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 12] Loss: 0.3703 | Val Recall: 0.1351 | NDCG: 0.0696\n",
      "[Epoch 13] Loss: 0.3629 | Val Recall: 0.1306 | NDCG: 0.0673\n",
      "[Epoch 14] Loss: 0.3507 | Val Recall: 0.1306 | NDCG: 0.0687\n",
      "[Epoch 15] Loss: 0.3378 | Val Recall: 0.1336 | NDCG: 0.0709\n",
      "[Epoch 16] Loss: 0.3269 | Val Recall: 0.1351 | NDCG: 0.0730\n",
      "[Epoch 17] Loss: 0.3182 | Val Recall: 0.1366 | NDCG: 0.0747\n",
      "[Epoch 18] Loss: 0.3067 | Val Recall: 0.1366 | NDCG: 0.0753\n",
      "[Epoch 19] Loss: 0.3001 | Val Recall: 0.1366 | NDCG: 0.0756\n",
      "[Epoch 20] Loss: 0.2890 | Val Recall: 0.1411 | NDCG: 0.0768\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 21] Loss: 0.2861 | Val Recall: 0.1396 | NDCG: 0.0758\n",
      "[Epoch 22] Loss: 0.2779 | Val Recall: 0.1441 | NDCG: 0.0761\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 23] Loss: 0.2669 | Val Recall: 0.1441 | NDCG: 0.0762\n",
      "[Epoch 24] Loss: 0.2614 | Val Recall: 0.1456 | NDCG: 0.0770\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 25] Loss: 0.2542 | Val Recall: 0.1366 | NDCG: 0.0736\n",
      "\n",
      "=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: 24, Best Val Recall: 0.1456 ===\n",
      "\n",
      "=== Final Test Result (Best Model) ===\n",
      "Hit: 0.1562, Prec: 0.0156, Recall: 0.1562, NDCG: 0.0856\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4. lamda2 = 1e-4**"
   ],
   "metadata": {
    "id": "9qL0M5QUp6W-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "# 2. \ub370\uc774\ud130 \ub85c\ub4dc (Pre-split Data \uc0ac\uc6a9)\n",
    "# =========================================================\n",
    "if not os.path.exists(data_path) or not os.path.exists(movie_final_path):\n",
    "    print(\"Error: \ub370\uc774\ud130 \uacbd\ub85c\ub97c \ud655\uc778\ud574\uc8fc\uc138\uc694.\")\n",
    "else:\n",
    "    # 1. \ub370\uc774\ud130 \uc77d\uae30\n",
    "    train_df = pd.read_csv(f\"{data_path}/train.csv\")\n",
    "    val_df   = pd.read_csv(f\"{data_path}/val.csv\")\n",
    "    test_df  = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "    # 2. \ub9e4\ud551 \uc815\ubcf4 \ub85c\ub4dc\n",
    "    with open(f\"{data_path}/user2idx.pkl\", 'rb') as f: user2idx = pickle.load(f)\n",
    "    with open(f\"{data_path}/item2idx.pkl\", 'rb') as f: item2idx = pickle.load(f)\n",
    "\n",
    "    n_users = len(user2idx)\n",
    "    n_items = len(item2idx)\n",
    "\n",
    "    print(f\"\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: {n_users}, Item: {n_items}\")\n",
    "    print(f\"\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: {len(train_df)}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 3. \ub370\uc774\ud130 \ubd84\ub9ac (Positive vs Hard Negative)\n",
    "    # =========================================================\n",
    "    # 1) Positive Data (4\uc810 \uc774\uc0c1): \uadf8\ub798\ud504 \uc5f0\uacb0 \ubc0f \uc815\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_pos_df = train_df[train_df['rating'] >= 4.0].copy()\n",
    "\n",
    "    # 2) Hard Negative Data (2\uc810 \uc774\ud558): \uc624\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_neg_df = train_df[train_df['rating'] <= 2.0].copy()\n",
    "\n",
    "    print(f\"Positive Interactions (Graph\uc6a9): {len(train_pos_df)}\")\n",
    "    print(f\"Hard Negative Interactions: {len(train_neg_df)}\")\n",
    "\n",
    "    # \ub515\uc154\ub108\ub9ac \uc0dd\uc131\n",
    "    # Positive: \uc720\uc800\uac00 \uc88b\uc544\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d\n",
    "    user_pos_items = train_pos_df.groupby(\"user\")[\"item\"].apply(set).to_dict()\n",
    "\n",
    "    # Hard Negative: \uc720\uc800\uac00 \uc2eb\uc5b4\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d (\uc0d8\ud50c\ub9c1 \ub54c \uc0ac\uc6a9)\n",
    "    user_hard_neg_items = train_neg_df.groupby(\"user\")[\"item\"].apply(list).to_dict()\n",
    "\n",
    "    # =========================================================\n",
    "    # 4. Doc2Vec \ud559\uc2b5 \ubc0f \ub9e4\ud2b8\ub9ad\uc2a4 \uc0dd\uc131 (Feature Extraction)\n",
    "    # =========================================================\n",
    "    print(\"\\n=== Doc2Vec Training ===\")\n",
    "    movie_df = pd.read_csv(movie_final_path)\n",
    "    movie_df['overview_clean'] = movie_df['overview_clean'].fillna('unknown')\n",
    "\n",
    "    # TaggedDocument \uc0dd\uc131 (ID\ub294 \uc6d0\ubcf8 movieId \uc0ac\uc6a9 -> \ub098\uc911\uc5d0 item2idx\ub85c \ub9e4\ud551)\n",
    "    documents = [TaggedDocument(str(row['overview_clean']).split(), [str(row['movieId'])])\n",
    "                 for _, row in movie_df.iterrows()]\n",
    "\n",
    "    # LightGCN \ucc28\uc6d0(64)\uacfc \uc77c\uce58\uc2dc\ud0b4\n",
    "    d2v_model = Doc2Vec(documents, vector_size=64, window=5, min_count=1, workers=4, epochs=20, seed=42)\n",
    "\n",
    "    # Embedding Matrix \uc0dd\uc131 (item_idx \uc21c\uc11c\uc5d0 \ub9de\uac8c \uc815\ub82c)\n",
    "    doc2vec_weights = np.zeros((n_items, 64))\n",
    "    cnt = 0\n",
    "    for movie_id, idx in item2idx.items():\n",
    "        # Doc2Vec \ubaa8\ub378\uc5d0 \ud574\ub2f9 \uc601\ud654 ID\uac00 \uc788\ub294\uc9c0 \ud655\uc778\n",
    "        if str(movie_id) in d2v_model.dv:\n",
    "            doc2vec_weights[idx] = d2v_model.dv[str(movie_id)]\n",
    "            cnt += 1\n",
    "        else:\n",
    "            # \uc5c6\uc73c\uba74 \ub79c\ub364 \ucd08\uae30\ud654 (\uc791\uc740 \uac12)\n",
    "            doc2vec_weights[idx] = np.random.normal(0, 0.01, 64)\n",
    "\n",
    "    doc2vec_weights = torch.FloatTensor(doc2vec_weights).to(device)\n",
    "    print(f\"Doc2Vec Matrix Created. Mapped: {cnt}/{n_items}\")\n",
    "\n",
    "\n",
    "    # Save Doc2Vec embeddings to disk for reuse\n",
    "    doc2vec_save_path = f\"{base_path}/doc2vec_embeddings_64d.pkl\"\n",
    "    with open(doc2vec_save_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'embeddings': doc2vec_weights.cpu().numpy(),\n",
    "            'item2idx': item2idx,\n",
    "            'n_items': n_items,\n",
    "            'vector_size': 64,\n",
    "            'created_at': str(pd.Timestamp.now())\n",
    "        }, f)\n",
    "    print(f\"\u2705 Doc2Vec embeddings saved to: {doc2vec_save_path}\")\n",
    "    # =========================================================\n",
    "    # 5. LightGCN\uc6a9 \uc778\uc811\ud589\ub82c \uc0dd\uc131 (Positive \ub370\uc774\ud130\ub9cc \uc0ac\uc6a9!)\n",
    "    # =========================================================\n",
    "    def get_adj_mat(n_users, n_items, pos_df):\n",
    "        \"\"\"\n",
    "        \ubc18\ub4dc\uc2dc 4\uc810 \uc774\uc0c1\uc778 pos_df\ub9cc \ub123\uc5b4\uc11c \uadf8\ub798\ud504\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud568\n",
    "        \"\"\"\n",
    "        n_nodes = n_users + n_items\n",
    "        user_np = pos_df['user'].values\n",
    "        item_np = pos_df['item'].values\n",
    "\n",
    "        R = sp.coo_matrix((np.ones(len(user_np)), (user_np, item_np)), shape=(n_users, n_items))\n",
    "\n",
    "        top_part = sp.hstack([sp.csr_matrix((n_users, n_users)), R])\n",
    "        bot_part = sp.hstack([R.T, sp.csr_matrix((n_items, n_items))])\n",
    "        A = sp.vstack([top_part, bot_part])\n",
    "\n",
    "        rowsum = np.array(A.sum(1))\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "\n",
    "        norm_adj = d_mat_inv_sqrt.dot(A).dot(d_mat_inv_sqrt).tocoo()\n",
    "        indices = torch.LongTensor(np.vstack((norm_adj.row, norm_adj.col)))\n",
    "        values = torch.FloatTensor(norm_adj.data)\n",
    "\n",
    "        return torch.sparse_coo_tensor(indices, values, torch.Size(norm_adj.shape)).to(device)\n",
    "\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\")\n",
    "    Adj_Matrix = get_adj_mat(n_users, n_items, train_pos_df)\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 6. \ubaa8\ub378 \uc815\uc758 (LightGCN with Doc2Vec Init)\n",
    "    # =========================================================\n",
    "    class LightGCN_Doc2Vec(nn.Module):\n",
    "        def __init__(self, n_users, n_items, dim, layers, A_hat, doc2vec_weights):\n",
    "            super().__init__()\n",
    "            self.n_users = n_users\n",
    "            self.n_items = n_items\n",
    "            self.dim = dim\n",
    "            self.layers = layers\n",
    "            self.A_hat = A_hat\n",
    "\n",
    "            # User\ub294 \ub79c\ub364 \ucd08\uae30\ud654\n",
    "            self.user_emb = nn.Embedding(n_users, dim)\n",
    "            nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "\n",
    "            # [\ud575\uc2ec] Item\uc740 Doc2Vec\uc73c\ub85c \ucd08\uae30\ud654 (freeze=False: \ud559\uc2b5 \uac00\ub2a5)\n",
    "            self.item_emb = nn.Embedding.from_pretrained(doc2vec_weights, freeze=False)\n",
    "\n",
    "            # Content Loss \uacc4\uc0b0\uc6a9 \uace0\uc815 \ubca1\ud130 (Buffer) - \ud559\uc2b5 \uc548 \ub428\n",
    "            self.register_buffer('fixed_doc2vec', doc2vec_weights.clone().detach())\n",
    "\n",
    "        def get_all_embeddings(self):\n",
    "            users = self.user_emb.weight\n",
    "            items = self.item_emb.weight\n",
    "            all_emb = torch.cat([users, items], dim=0)\n",
    "\n",
    "            embs = [all_emb]\n",
    "            for _ in range(self.layers):\n",
    "                all_emb = torch.sparse.mm(self.A_hat, all_emb)\n",
    "                embs.append(all_emb)\n",
    "\n",
    "            out = torch.stack(embs, dim=0).mean(dim=0)\n",
    "            return out[:self.n_users], out[self.n_users:]\n",
    "\n",
    "    # =========================================================\n",
    "    # 7. Loss & Sampling (Hard Negative + Content Loss)\n",
    "    # =========================================================\n",
    "    def sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5):\n",
    "        users = np.random.choice(list(user_pos_items.keys()), size=batch_size)\n",
    "        pos = []\n",
    "        neg = []\n",
    "\n",
    "        for u in users:\n",
    "            # Positive Sampling\n",
    "            pos.append(np.random.choice(list(user_pos_items[u])))\n",
    "\n",
    "            # Hard Negative Sampling (50% \ud655\ub960)\n",
    "            if (u in user_hard_neg_items) and (len(user_hard_neg_items[u]) > 0) and (random.random() < hard_prob):\n",
    "                neg.append(np.random.choice(user_hard_neg_items[u]))\n",
    "            else:\n",
    "                # Random Negative\n",
    "                while True:\n",
    "                    n = np.random.randint(0, n_items)\n",
    "                    if n not in user_pos_items[u]:\n",
    "                        neg.append(n); break\n",
    "\n",
    "        return (torch.LongTensor(users).to(device),\n",
    "                torch.LongTensor(pos).to(device),\n",
    "                torch.LongTensor(neg).to(device))\n",
    "\n",
    "    def bpr_loss_with_content(u_f, i_pos_f, i_neg_f, u_0, i_pos_0, i_neg_0, fixed_vec, lambda1, lambda2):\n",
    "        \"\"\"\n",
    "        u_f, i_pos_f, i_neg_f : \uc804\ud30c\ub41c \uc784\ubca0\ub529 (BPR\uc6a9)\n",
    "        u_0, i_pos_0, i_neg_0 : \ucd08\uae30 \uc784\ubca0\ub529 (Regularization\uc6a9)\n",
    "        fixed_vec             : \uace0\uc815\ub41c Doc2Vec \ubca1\ud130 (Content Loss\uc6a9)\n",
    "        \"\"\"\n",
    "        # 1. BPR Loss\n",
    "        pos_scores = (u_f * i_pos_f).sum(dim=1)\n",
    "        neg_scores = (u_f * i_neg_f).sum(dim=1)\n",
    "        bpr_loss = torch.mean(torch.nn.functional.softplus(-(pos_scores - neg_scores)))\n",
    "\n",
    "        # 2. L2 Regularization (E^0 \uae30\uc900)\n",
    "        reg_loss = 0.5 * (u_0.norm(2).pow(2) + i_pos_0.norm(2).pow(2) + i_neg_0.norm(2).pow(2)) / u_0.size(0)\n",
    "\n",
    "        # 3. Content Loss (E^0 vs Fixed Doc2Vec)\n",
    "        content_loss = F.mse_loss(i_pos_0, fixed_vec)\n",
    "\n",
    "        return bpr_loss + lambda1 * reg_loss + lambda2 * content_loss\n",
    "\n",
    "    # =========================================================\n",
    "    # 8. \ud3c9\uac00 \ud568\uc218 (Precision, Recall, NDCG, HitRate)\n",
    "    # =========================================================\n",
    "    def ndcg_at_k(rank, k):\n",
    "        if rank is None or rank >= k: return 0.0\n",
    "        return 1.0 / math.log2(rank + 2)\n",
    "\n",
    "    def evaluate(model, df_eval, k=10):\n",
    "        model.eval()\n",
    "        users_final, items_final = model.get_all_embeddings()\n",
    "        hits, ndcg, precision, recall, total_users = 0, 0, 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for u_idx, group in df_eval.groupby('user'):\n",
    "                total_users += 1\n",
    "                target_items = set(group['item'].values)\n",
    "\n",
    "                scores = torch.matmul(users_final[u_idx], items_final.t())\n",
    "\n",
    "                # Train\uc5d0\uc11c \ubcf8 \uc544\uc774\ud15c(Positive Only)\uc740 \ub9c8\uc2a4\ud0b9\n",
    "                if u_idx in user_pos_items:\n",
    "                    scores[list(user_pos_items[u_idx])] = -1e9\n",
    "\n",
    "                _, topk = torch.topk(scores, k)\n",
    "                topk = topk.cpu().tolist()\n",
    "\n",
    "                num_correct = 0\n",
    "                dcg, idcg = 0.0, 0.0\n",
    "\n",
    "                for i, item_id in enumerate(topk):\n",
    "                    if item_id in target_items:\n",
    "                        num_correct += 1\n",
    "                        dcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                num_targets = len(target_items)\n",
    "                for i in range(min(num_targets, k)):\n",
    "                    idcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                if num_correct > 0: hits += 1\n",
    "                precision += num_correct / k\n",
    "                recall += num_correct / num_targets\n",
    "                if idcg > 0: ndcg += dcg / idcg\n",
    "\n",
    "        return {'HitRate': hits/total_users, 'Precision': precision/total_users, 'Recall': recall/total_users, 'NDCG': ndcg/total_users}\n",
    "\n",
    "    # =========================================================\n",
    "    # 9. \ud559\uc2b5 \uc2e4\ud589 (Best Model Selection \uc801\uc6a9)\n",
    "    # =========================================================\n",
    "    dim = 64\n",
    "    layers = 3\n",
    "    batch_size = 1024\n",
    "    epochs = 25\n",
    "    lr = 1e-3\n",
    "\n",
    "    # [\uc124\uc815] \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\n",
    "    lambda1 = 1e-5  # Reg (Base \uc2e4\ud5d8 \uacb0\uacfc \ubc18\uc601)\n",
    "    lambda2 = 1e-4  # Content Loss (Doc2Vec Init\ub9cc \uc4f0\ub824\uba74 0, \uaddc\uc81c\ud558\ub824\uba74 1e-3 \ub4f1)\n",
    "\n",
    "    model = LightGCN_Doc2Vec(n_users, n_items, dim, layers, Adj_Matrix, doc2vec_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Best Model \uc800\uc7a5 \ubcc0\uc218\n",
    "    best_recall = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_path = \"best_doc2vec_lightgcn.pt\"\n",
    "\n",
    "    print(f\"\\n=== Training Start (Lambda2={lambda2}, Hard Negative Applied) ===\")\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # \ubc30\uce58 \uc218\ub294 Positive Data \uae30\uc900\n",
    "        num_batches = len(train_pos_df) // batch_size + 1\n",
    "\n",
    "        for _ in range(num_batches):\n",
    "            # 1. \uc0d8\ud50c\ub9c1 (Hard Negative \ud3ec\ud568)\n",
    "            users, pos, neg = sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5)\n",
    "\n",
    "            # 2. \uc804\ud30c (BPR \uc6a9)\n",
    "            u_final, i_final = model.get_all_embeddings()\n",
    "            u_f = u_final[users]\n",
    "            i_pos_f = i_final[pos]\n",
    "            i_neg_f = i_final[neg]\n",
    "\n",
    "            # 3. \ucd08\uae30\uac12 (Reg & Content \uc6a9)\n",
    "            u_0 = model.user_emb.weight[users]\n",
    "            i_pos_0 = model.item_emb.weight[pos]\n",
    "            i_neg_0 = model.item_emb.weight[neg]\n",
    "\n",
    "            # 4. \uace0\uc815\ub41c Doc2Vec \ucd94\ucd9c\n",
    "            fixed_vec = model.fixed_doc2vec[pos]\n",
    "\n",
    "            # 5. Loss \uacc4\uc0b0\n",
    "            loss = bpr_loss_with_content(u_f, i_pos_f, i_neg_f,\n",
    "                                         u_0, i_pos_0, i_neg_0,\n",
    "                                         fixed_vec, lambda1, lambda2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # \ub9e4 Epoch\ub9c8\ub2e4 Validation \ud3c9\uac00\n",
    "        val_metrics = evaluate(model, val_df, k=10)\n",
    "        current_recall = val_metrics['Recall']\n",
    "\n",
    "        print(f\"[Epoch {epoch:02d}] Loss: {total_loss/num_batches:.4f} | Val Recall: {current_recall:.4f} | NDCG: {val_metrics['NDCG']:.4f}\")\n",
    "\n",
    "        if current_recall > best_recall:\n",
    "            best_recall = current_recall\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"   >>> Best Model Updated!\")\n",
    "\n",
    "    print(f\"\\n=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: {best_epoch}, Best Val Recall: {best_recall:.4f} ===\")\n",
    "\n",
    "    # Final Test with Best Model\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    test_metrics = evaluate(model, test_df, k=10)\n",
    "    print(\"\\n=== Final Test Result (Best Model) ===\")\n",
    "    print(f\"Hit: {test_metrics['HitRate']:.4f}, Prec: {test_metrics['Precision']:.4f}, Recall: {test_metrics['Recall']:.4f}, NDCG: {test_metrics['NDCG']:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2x3xGg5pv_T",
    "outputId": "0f9a1b99-eb50-46d8-ae13-e96dcea567bc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: 671, Item: 3485\n",
      "\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: 88595\n",
      "Positive Interactions (Graph\uc6a9): 46243\n",
      "Hard Negative Interactions: 11327\n",
      "\n",
      "=== Doc2Vec Training ===\n",
      "Doc2Vec Matrix Created. Mapped: 3485/3485\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\n",
      "\n",
      "=== Training Start (Lambda2=0.0001, Hard Negative Applied) ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-3566950766.py:88: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch 01] Loss: 0.6457 | Val Recall: 0.1021 | NDCG: 0.0568\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 02] Loss: 0.5934 | Val Recall: 0.1081 | NDCG: 0.0582\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 03] Loss: 0.5355 | Val Recall: 0.1216 | NDCG: 0.0648\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 04] Loss: 0.4895 | Val Recall: 0.1231 | NDCG: 0.0653\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 05] Loss: 0.4632 | Val Recall: 0.1276 | NDCG: 0.0668\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 06] Loss: 0.4416 | Val Recall: 0.1291 | NDCG: 0.0674\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 07] Loss: 0.4287 | Val Recall: 0.1276 | NDCG: 0.0667\n",
      "[Epoch 08] Loss: 0.4174 | Val Recall: 0.1336 | NDCG: 0.0687\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 09] Loss: 0.4066 | Val Recall: 0.1336 | NDCG: 0.0678\n",
      "[Epoch 10] Loss: 0.3958 | Val Recall: 0.1336 | NDCG: 0.0678\n",
      "[Epoch 11] Loss: 0.3807 | Val Recall: 0.1336 | NDCG: 0.0688\n",
      "[Epoch 12] Loss: 0.3693 | Val Recall: 0.1366 | NDCG: 0.0701\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 13] Loss: 0.3562 | Val Recall: 0.1336 | NDCG: 0.0694\n",
      "[Epoch 14] Loss: 0.3454 | Val Recall: 0.1366 | NDCG: 0.0708\n",
      "[Epoch 15] Loss: 0.3367 | Val Recall: 0.1381 | NDCG: 0.0723\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 16] Loss: 0.3244 | Val Recall: 0.1306 | NDCG: 0.0716\n",
      "[Epoch 17] Loss: 0.3102 | Val Recall: 0.1336 | NDCG: 0.0715\n",
      "[Epoch 18] Loss: 0.3066 | Val Recall: 0.1291 | NDCG: 0.0710\n",
      "[Epoch 19] Loss: 0.2957 | Val Recall: 0.1306 | NDCG: 0.0728\n",
      "[Epoch 20] Loss: 0.2861 | Val Recall: 0.1351 | NDCG: 0.0744\n",
      "[Epoch 21] Loss: 0.2793 | Val Recall: 0.1366 | NDCG: 0.0752\n",
      "[Epoch 22] Loss: 0.2708 | Val Recall: 0.1366 | NDCG: 0.0748\n",
      "[Epoch 23] Loss: 0.2657 | Val Recall: 0.1336 | NDCG: 0.0742\n",
      "[Epoch 24] Loss: 0.2584 | Val Recall: 0.1351 | NDCG: 0.0736\n",
      "[Epoch 25] Loss: 0.2519 | Val Recall: 0.1351 | NDCG: 0.0740\n",
      "\n",
      "=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: 15, Best Val Recall: 0.1381 ===\n",
      "\n",
      "=== Final Test Result (Best Model) ===\n",
      "Hit: 0.1456, Prec: 0.0146, Recall: 0.1456, NDCG: 0.0751\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**5. lamda2 = 1e-1**"
   ],
   "metadata": {
    "id": "iUgiYxUEqkJ8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# =========================================================\n",
    "# 2. \ub370\uc774\ud130 \ub85c\ub4dc (Pre-split Data \uc0ac\uc6a9)\n",
    "# =========================================================\n",
    "if not os.path.exists(data_path) or not os.path.exists(movie_final_path):\n",
    "    print(\"Error: \ub370\uc774\ud130 \uacbd\ub85c\ub97c \ud655\uc778\ud574\uc8fc\uc138\uc694.\")\n",
    "else:\n",
    "    # 1. \ub370\uc774\ud130 \uc77d\uae30\n",
    "    train_df = pd.read_csv(f\"{data_path}/train.csv\")\n",
    "    val_df   = pd.read_csv(f\"{data_path}/val.csv\")\n",
    "    test_df  = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "    # 2. \ub9e4\ud551 \uc815\ubcf4 \ub85c\ub4dc\n",
    "    with open(f\"{data_path}/user2idx.pkl\", 'rb') as f: user2idx = pickle.load(f)\n",
    "    with open(f\"{data_path}/item2idx.pkl\", 'rb') as f: item2idx = pickle.load(f)\n",
    "\n",
    "    n_users = len(user2idx)\n",
    "    n_items = len(item2idx)\n",
    "\n",
    "    print(f\"\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: {n_users}, Item: {n_items}\")\n",
    "    print(f\"\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: {len(train_df)}\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 3. \ub370\uc774\ud130 \ubd84\ub9ac (Positive vs Hard Negative)\n",
    "    # =========================================================\n",
    "    # 1) Positive Data (4\uc810 \uc774\uc0c1): \uadf8\ub798\ud504 \uc5f0\uacb0 \ubc0f \uc815\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_pos_df = train_df[train_df['rating'] >= 4.0].copy()\n",
    "\n",
    "    # 2) Hard Negative Data (2\uc810 \uc774\ud558): \uc624\ub2f5 \ud559\uc2b5\uc6a9\n",
    "    train_neg_df = train_df[train_df['rating'] <= 2.0].copy()\n",
    "\n",
    "    print(f\"Positive Interactions (Graph\uc6a9): {len(train_pos_df)}\")\n",
    "    print(f\"Hard Negative Interactions: {len(train_neg_df)}\")\n",
    "\n",
    "    # \ub515\uc154\ub108\ub9ac \uc0dd\uc131\n",
    "    # Positive: \uc720\uc800\uac00 \uc88b\uc544\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d\n",
    "    user_pos_items = train_pos_df.groupby(\"user\")[\"item\"].apply(set).to_dict()\n",
    "\n",
    "    # Hard Negative: \uc720\uc800\uac00 \uc2eb\uc5b4\ud558\ub294 \uc544\uc774\ud15c \ubaa9\ub85d (\uc0d8\ud50c\ub9c1 \ub54c \uc0ac\uc6a9)\n",
    "    user_hard_neg_items = train_neg_df.groupby(\"user\")[\"item\"].apply(list).to_dict()\n",
    "\n",
    "    # =========================================================\n",
    "    # 4. Doc2Vec \ud559\uc2b5 \ubc0f \ub9e4\ud2b8\ub9ad\uc2a4 \uc0dd\uc131 (Feature Extraction)\n",
    "    # =========================================================\n",
    "    print(\"\\n=== Doc2Vec Training ===\")\n",
    "    movie_df = pd.read_csv(movie_final_path)\n",
    "    movie_df['overview_clean'] = movie_df['overview_clean'].fillna('unknown')\n",
    "\n",
    "    # TaggedDocument \uc0dd\uc131 (ID\ub294 \uc6d0\ubcf8 movieId \uc0ac\uc6a9 -> \ub098\uc911\uc5d0 item2idx\ub85c \ub9e4\ud551)\n",
    "    documents = [TaggedDocument(str(row['overview_clean']).split(), [str(row['movieId'])])\n",
    "                 for _, row in movie_df.iterrows()]\n",
    "\n",
    "    # LightGCN \ucc28\uc6d0(64)\uacfc \uc77c\uce58\uc2dc\ud0b4\n",
    "    d2v_model = Doc2Vec(documents, vector_size=64, window=5, min_count=1, workers=4, epochs=20, seed=42)\n",
    "\n",
    "    # Embedding Matrix \uc0dd\uc131 (item_idx \uc21c\uc11c\uc5d0 \ub9de\uac8c \uc815\ub82c)\n",
    "    doc2vec_weights = np.zeros((n_items, 64))\n",
    "    cnt = 0\n",
    "    for movie_id, idx in item2idx.items():\n",
    "        # Doc2Vec \ubaa8\ub378\uc5d0 \ud574\ub2f9 \uc601\ud654 ID\uac00 \uc788\ub294\uc9c0 \ud655\uc778\n",
    "        if str(movie_id) in d2v_model.dv:\n",
    "            doc2vec_weights[idx] = d2v_model.dv[str(movie_id)]\n",
    "            cnt += 1\n",
    "        else:\n",
    "            # \uc5c6\uc73c\uba74 \ub79c\ub364 \ucd08\uae30\ud654 (\uc791\uc740 \uac12)\n",
    "            doc2vec_weights[idx] = np.random.normal(0, 0.01, 64)\n",
    "\n",
    "    doc2vec_weights = torch.FloatTensor(doc2vec_weights).to(device)\n",
    "    print(f\"Doc2Vec Matrix Created. Mapped: {cnt}/{n_items}\")\n",
    "\n",
    "\n",
    "    # Save Doc2Vec embeddings to disk for reuse\n",
    "    doc2vec_save_path = f\"{base_path}/doc2vec_embeddings_64d.pkl\"\n",
    "    with open(doc2vec_save_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'embeddings': doc2vec_weights.cpu().numpy(),\n",
    "            'item2idx': item2idx,\n",
    "            'n_items': n_items,\n",
    "            'vector_size': 64,\n",
    "            'created_at': str(pd.Timestamp.now())\n",
    "        }, f)\n",
    "    print(f\"\u2705 Doc2Vec embeddings saved to: {doc2vec_save_path}\")\n",
    "    # =========================================================\n",
    "    # 5. LightGCN\uc6a9 \uc778\uc811\ud589\ub82c \uc0dd\uc131 (Positive \ub370\uc774\ud130\ub9cc \uc0ac\uc6a9!)\n",
    "    # =========================================================\n",
    "    def get_adj_mat(n_users, n_items, pos_df):\n",
    "        \"\"\"\n",
    "        \ubc18\ub4dc\uc2dc 4\uc810 \uc774\uc0c1\uc778 pos_df\ub9cc \ub123\uc5b4\uc11c \uadf8\ub798\ud504\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud568\n",
    "        \"\"\"\n",
    "        n_nodes = n_users + n_items\n",
    "        user_np = pos_df['user'].values\n",
    "        item_np = pos_df['item'].values\n",
    "\n",
    "        R = sp.coo_matrix((np.ones(len(user_np)), (user_np, item_np)), shape=(n_users, n_items))\n",
    "\n",
    "        top_part = sp.hstack([sp.csr_matrix((n_users, n_users)), R])\n",
    "        bot_part = sp.hstack([R.T, sp.csr_matrix((n_items, n_items))])\n",
    "        A = sp.vstack([top_part, bot_part])\n",
    "\n",
    "        rowsum = np.array(A.sum(1))\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "\n",
    "        norm_adj = d_mat_inv_sqrt.dot(A).dot(d_mat_inv_sqrt).tocoo()\n",
    "        indices = torch.LongTensor(np.vstack((norm_adj.row, norm_adj.col)))\n",
    "        values = torch.FloatTensor(norm_adj.data)\n",
    "\n",
    "        return torch.sparse_coo_tensor(indices, values, torch.Size(norm_adj.shape)).to(device)\n",
    "\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\")\n",
    "    Adj_Matrix = get_adj_mat(n_users, n_items, train_pos_df)\n",
    "    print(\"\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\")\n",
    "\n",
    "    # =========================================================\n",
    "    # 6. \ubaa8\ub378 \uc815\uc758 (LightGCN with Doc2Vec Init)\n",
    "    # =========================================================\n",
    "    class LightGCN_Doc2Vec(nn.Module):\n",
    "        def __init__(self, n_users, n_items, dim, layers, A_hat, doc2vec_weights):\n",
    "            super().__init__()\n",
    "            self.n_users = n_users\n",
    "            self.n_items = n_items\n",
    "            self.dim = dim\n",
    "            self.layers = layers\n",
    "            self.A_hat = A_hat\n",
    "\n",
    "            # User\ub294 \ub79c\ub364 \ucd08\uae30\ud654\n",
    "            self.user_emb = nn.Embedding(n_users, dim)\n",
    "            nn.init.normal_(self.user_emb.weight, std=0.1)\n",
    "\n",
    "            # [\ud575\uc2ec] Item\uc740 Doc2Vec\uc73c\ub85c \ucd08\uae30\ud654 (freeze=False: \ud559\uc2b5 \uac00\ub2a5)\n",
    "            self.item_emb = nn.Embedding.from_pretrained(doc2vec_weights, freeze=False)\n",
    "\n",
    "            # Content Loss \uacc4\uc0b0\uc6a9 \uace0\uc815 \ubca1\ud130 (Buffer) - \ud559\uc2b5 \uc548 \ub428\n",
    "            self.register_buffer('fixed_doc2vec', doc2vec_weights.clone().detach())\n",
    "\n",
    "        def get_all_embeddings(self):\n",
    "            users = self.user_emb.weight\n",
    "            items = self.item_emb.weight\n",
    "            all_emb = torch.cat([users, items], dim=0)\n",
    "\n",
    "            embs = [all_emb]\n",
    "            for _ in range(self.layers):\n",
    "                all_emb = torch.sparse.mm(self.A_hat, all_emb)\n",
    "                embs.append(all_emb)\n",
    "\n",
    "            out = torch.stack(embs, dim=0).mean(dim=0)\n",
    "            return out[:self.n_users], out[self.n_users:]\n",
    "\n",
    "    # =========================================================\n",
    "    # 7. Loss & Sampling (Hard Negative + Content Loss)\n",
    "    # =========================================================\n",
    "    def sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5):\n",
    "        users = np.random.choice(list(user_pos_items.keys()), size=batch_size)\n",
    "        pos = []\n",
    "        neg = []\n",
    "\n",
    "        for u in users:\n",
    "            # Positive Sampling\n",
    "            pos.append(np.random.choice(list(user_pos_items[u])))\n",
    "\n",
    "            # Hard Negative Sampling (50% \ud655\ub960)\n",
    "            if (u in user_hard_neg_items) and (len(user_hard_neg_items[u]) > 0) and (random.random() < hard_prob):\n",
    "                neg.append(np.random.choice(user_hard_neg_items[u]))\n",
    "            else:\n",
    "                # Random Negative\n",
    "                while True:\n",
    "                    n = np.random.randint(0, n_items)\n",
    "                    if n not in user_pos_items[u]:\n",
    "                        neg.append(n); break\n",
    "\n",
    "        return (torch.LongTensor(users).to(device),\n",
    "                torch.LongTensor(pos).to(device),\n",
    "                torch.LongTensor(neg).to(device))\n",
    "\n",
    "    def bpr_loss_with_content(u_f, i_pos_f, i_neg_f, u_0, i_pos_0, i_neg_0, fixed_vec, lambda1, lambda2):\n",
    "        \"\"\"\n",
    "        u_f, i_pos_f, i_neg_f : \uc804\ud30c\ub41c \uc784\ubca0\ub529 (BPR\uc6a9)\n",
    "        u_0, i_pos_0, i_neg_0 : \ucd08\uae30 \uc784\ubca0\ub529 (Regularization\uc6a9)\n",
    "        fixed_vec             : \uace0\uc815\ub41c Doc2Vec \ubca1\ud130 (Content Loss\uc6a9)\n",
    "        \"\"\"\n",
    "        # 1. BPR Loss\n",
    "        pos_scores = (u_f * i_pos_f).sum(dim=1)\n",
    "        neg_scores = (u_f * i_neg_f).sum(dim=1)\n",
    "        bpr_loss = torch.mean(torch.nn.functional.softplus(-(pos_scores - neg_scores)))\n",
    "\n",
    "        # 2. L2 Regularization (E^0 \uae30\uc900)\n",
    "        reg_loss = 0.5 * (u_0.norm(2).pow(2) + i_pos_0.norm(2).pow(2) + i_neg_0.norm(2).pow(2)) / u_0.size(0)\n",
    "\n",
    "        # 3. Content Loss (E^0 vs Fixed Doc2Vec)\n",
    "        content_loss = F.mse_loss(i_pos_0, fixed_vec)\n",
    "\n",
    "        return bpr_loss + lambda1 * reg_loss + lambda2 * content_loss\n",
    "\n",
    "    # =========================================================\n",
    "    # 8. \ud3c9\uac00 \ud568\uc218 (Precision, Recall, NDCG, HitRate)\n",
    "    # =========================================================\n",
    "    def ndcg_at_k(rank, k):\n",
    "        if rank is None or rank >= k: return 0.0\n",
    "        return 1.0 / math.log2(rank + 2)\n",
    "\n",
    "    def evaluate(model, df_eval, k=10):\n",
    "        model.eval()\n",
    "        users_final, items_final = model.get_all_embeddings()\n",
    "        hits, ndcg, precision, recall, total_users = 0, 0, 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for u_idx, group in df_eval.groupby('user'):\n",
    "                total_users += 1\n",
    "                target_items = set(group['item'].values)\n",
    "\n",
    "                scores = torch.matmul(users_final[u_idx], items_final.t())\n",
    "\n",
    "                # Train\uc5d0\uc11c \ubcf8 \uc544\uc774\ud15c(Positive Only)\uc740 \ub9c8\uc2a4\ud0b9\n",
    "                if u_idx in user_pos_items:\n",
    "                    scores[list(user_pos_items[u_idx])] = -1e9\n",
    "\n",
    "                _, topk = torch.topk(scores, k)\n",
    "                topk = topk.cpu().tolist()\n",
    "\n",
    "                num_correct = 0\n",
    "                dcg, idcg = 0.0, 0.0\n",
    "\n",
    "                for i, item_id in enumerate(topk):\n",
    "                    if item_id in target_items:\n",
    "                        num_correct += 1\n",
    "                        dcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                num_targets = len(target_items)\n",
    "                for i in range(min(num_targets, k)):\n",
    "                    idcg += 1.0 / np.log2(i + 2)\n",
    "\n",
    "                if num_correct > 0: hits += 1\n",
    "                precision += num_correct / k\n",
    "                recall += num_correct / num_targets\n",
    "                if idcg > 0: ndcg += dcg / idcg\n",
    "\n",
    "        return {'HitRate': hits/total_users, 'Precision': precision/total_users, 'Recall': recall/total_users, 'NDCG': ndcg/total_users}\n",
    "\n",
    "    # =========================================================\n",
    "    # 9. \ud559\uc2b5 \uc2e4\ud589 (Best Model Selection \uc801\uc6a9)\n",
    "    # =========================================================\n",
    "    dim = 64\n",
    "    layers = 3\n",
    "    batch_size = 1024\n",
    "    epochs = 25\n",
    "    lr = 1e-3\n",
    "\n",
    "    # [\uc124\uc815] \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\n",
    "    lambda1 = 1e-5  # Reg (Base \uc2e4\ud5d8 \uacb0\uacfc \ubc18\uc601)\n",
    "    lambda2 = 1e-1  # Content Loss (Doc2Vec Init\ub9cc \uc4f0\ub824\uba74 0, \uaddc\uc81c\ud558\ub824\uba74 1e-3 \ub4f1)\n",
    "\n",
    "    model = LightGCN_Doc2Vec(n_users, n_items, dim, layers, Adj_Matrix, doc2vec_weights).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Best Model \uc800\uc7a5 \ubcc0\uc218\n",
    "    best_recall = 0.0\n",
    "    best_epoch = 0\n",
    "    best_model_path = \"best_doc2vec_lightgcn.pt\"\n",
    "\n",
    "    print(f\"\\n=== Training Start (Lambda2={lambda2}, Hard Negative Applied) ===\")\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # \ubc30\uce58 \uc218\ub294 Positive Data \uae30\uc900\n",
    "        num_batches = len(train_pos_df) // batch_size + 1\n",
    "\n",
    "        for _ in range(num_batches):\n",
    "            # 1. \uc0d8\ud50c\ub9c1 (Hard Negative \ud3ec\ud568)\n",
    "            users, pos, neg = sample_batch_with_hard_neg(batch_size, user_pos_items, user_hard_neg_items, n_items, hard_prob=0.5)\n",
    "\n",
    "            # 2. \uc804\ud30c (BPR \uc6a9)\n",
    "            u_final, i_final = model.get_all_embeddings()\n",
    "            u_f = u_final[users]\n",
    "            i_pos_f = i_final[pos]\n",
    "            i_neg_f = i_final[neg]\n",
    "\n",
    "            # 3. \ucd08\uae30\uac12 (Reg & Content \uc6a9)\n",
    "            u_0 = model.user_emb.weight[users]\n",
    "            i_pos_0 = model.item_emb.weight[pos]\n",
    "            i_neg_0 = model.item_emb.weight[neg]\n",
    "\n",
    "            # 4. \uace0\uc815\ub41c Doc2Vec \ucd94\ucd9c\n",
    "            fixed_vec = model.fixed_doc2vec[pos]\n",
    "\n",
    "            # 5. Loss \uacc4\uc0b0\n",
    "            loss = bpr_loss_with_content(u_f, i_pos_f, i_neg_f,\n",
    "                                         u_0, i_pos_0, i_neg_0,\n",
    "                                         fixed_vec, lambda1, lambda2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # \ub9e4 Epoch\ub9c8\ub2e4 Validation \ud3c9\uac00\n",
    "        val_metrics = evaluate(model, val_df, k=10)\n",
    "        current_recall = val_metrics['Recall']\n",
    "\n",
    "        print(f\"[Epoch {epoch:02d}] Loss: {total_loss/num_batches:.4f} | Val Recall: {current_recall:.4f} | NDCG: {val_metrics['NDCG']:.4f}\")\n",
    "\n",
    "        if current_recall > best_recall:\n",
    "            best_recall = current_recall\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"   >>> Best Model Updated!\")\n",
    "\n",
    "    print(f\"\\n=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: {best_epoch}, Best Val Recall: {best_recall:.4f} ===\")\n",
    "\n",
    "    # Final Test with Best Model\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    test_metrics = evaluate(model, test_df, k=10)\n",
    "    print(\"\\n=== Final Test Result (Best Model) ===\")\n",
    "    print(f\"Hit: {test_metrics['HitRate']:.4f}, Prec: {test_metrics['Precision']:.4f}, Recall: {test_metrics['Recall']:.4f}, NDCG: {test_metrics['NDCG']:.4f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5NdlhJdqZrq",
    "outputId": "c64a17a2-19ab-4460-f65e-d537b43eba6a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\ub370\uc774\ud130 \ub85c\ub4dc \uc644\ub8cc. User: 671, Item: 3485\n",
      "\uc804\uccb4 Train \ub370\uc774\ud130 \uc218: 88595\n",
      "Positive Interactions (Graph\uc6a9): 46243\n",
      "Hard Negative Interactions: 11327\n",
      "\n",
      "=== Doc2Vec Training ===\n",
      "Doc2Vec Matrix Created. Mapped: 3485/3485\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc911 (Positive Edge Only)...\n",
      "\uadf8\ub798\ud504 \uc0dd\uc131 \uc644\ub8cc!\n",
      "\n",
      "=== Training Start (Lambda2=0.1, Hard Negative Applied) ===\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-2129904723.py:88: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch 01] Loss: 0.6462 | Val Recall: 0.1006 | NDCG: 0.0556\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 02] Loss: 0.5943 | Val Recall: 0.1096 | NDCG: 0.0585\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 03] Loss: 0.5386 | Val Recall: 0.1201 | NDCG: 0.0637\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 04] Loss: 0.4923 | Val Recall: 0.1201 | NDCG: 0.0644\n",
      "[Epoch 05] Loss: 0.4627 | Val Recall: 0.1246 | NDCG: 0.0659\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 06] Loss: 0.4437 | Val Recall: 0.1291 | NDCG: 0.0672\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 07] Loss: 0.4305 | Val Recall: 0.1336 | NDCG: 0.0691\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 08] Loss: 0.4152 | Val Recall: 0.1351 | NDCG: 0.0691\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 09] Loss: 0.4039 | Val Recall: 0.1396 | NDCG: 0.0714\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 10] Loss: 0.3941 | Val Recall: 0.1366 | NDCG: 0.0700\n",
      "[Epoch 11] Loss: 0.3794 | Val Recall: 0.1411 | NDCG: 0.0725\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 12] Loss: 0.3714 | Val Recall: 0.1351 | NDCG: 0.0708\n",
      "[Epoch 13] Loss: 0.3561 | Val Recall: 0.1351 | NDCG: 0.0704\n",
      "[Epoch 14] Loss: 0.3483 | Val Recall: 0.1351 | NDCG: 0.0710\n",
      "[Epoch 15] Loss: 0.3373 | Val Recall: 0.1396 | NDCG: 0.0733\n",
      "[Epoch 16] Loss: 0.3274 | Val Recall: 0.1426 | NDCG: 0.0757\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 17] Loss: 0.3199 | Val Recall: 0.1441 | NDCG: 0.0761\n",
      "   >>> Best Model Updated!\n",
      "[Epoch 18] Loss: 0.3041 | Val Recall: 0.1411 | NDCG: 0.0748\n",
      "[Epoch 19] Loss: 0.3001 | Val Recall: 0.1441 | NDCG: 0.0762\n",
      "[Epoch 20] Loss: 0.2937 | Val Recall: 0.1381 | NDCG: 0.0741\n",
      "[Epoch 21] Loss: 0.2848 | Val Recall: 0.1351 | NDCG: 0.0743\n",
      "[Epoch 22] Loss: 0.2756 | Val Recall: 0.1351 | NDCG: 0.0748\n",
      "[Epoch 23] Loss: 0.2728 | Val Recall: 0.1351 | NDCG: 0.0749\n",
      "[Epoch 24] Loss: 0.2665 | Val Recall: 0.1351 | NDCG: 0.0751\n",
      "[Epoch 25] Loss: 0.2577 | Val Recall: 0.1366 | NDCG: 0.0751\n",
      "\n",
      "=== \ud559\uc2b5 \uc885\ub8cc. Best Epoch: 17, Best Val Recall: 0.1441 ===\n",
      "\n",
      "=== Final Test Result (Best Model) ===\n",
      "Hit: 0.1517, Prec: 0.0152, Recall: 0.1517, NDCG: 0.0802\n"
     ]
    }
   ]
  }
 ]
}