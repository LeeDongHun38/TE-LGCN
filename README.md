# Topic-Enhanced LightGCN (TE-LGCN)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

A novel recommendation system that enhances LightGCN with semantic content features through a dual enhancement strategy combining Doc2Vec embeddings and LDA topic modeling.

## ğŸ¯ Overview

**TE-LGCN (Topic-Enhanced LightGCN)** addresses the cold-start problem and improves recommendation quality by incorporating content-based semantic information into graph collaborative filtering. Unlike vanilla LightGCN which relies solely on user-item interactions, TE-LGCN leverages:

- **Semantic Initialization**: Doc2Vec embeddings from item content (e.g., movie plot summaries)
- **Structural Expansion**: LDA-extracted topics as bridge nodes in the user-item graph
- **Content Consistency**: A novel loss function that preserves semantic meaning during training

### Key Results

| Model | Recall@10 | Improvement |
|-------|-----------|-------------|
| Baseline LightGCN | ~0.159 | - |
| **TE-LGCN (k=10)** | **~0.200** | **+26.4%** |

---

## ğŸ”‘ Key Features

### 1. Dual Enhancement Strategy

#### Semantic Initialization (Doc2Vec)
- Pre-trained document embeddings initialize item representations
- Captures semantic similarity from textual content
- Reduces cold-start issues for new items

#### Structural Expansion (LDA Topics)
- Topic nodes create semantic bridges in the graph
- Heterogeneous graph: User-Item-Topic connections
- Enables recommendation via shared topic preferences

### 2. Content Consistency Loss

Combines three objectives:
```
L_total = L_BPR + Î»â‚ Â· L_reg + Î»â‚‚ Â· L_content

where:
- L_BPR: Bayesian Personalized Ranking loss
- L_reg: L2 regularization on embeddings
- L_content: L2 distance between learned and fixed Doc2Vec embeddings
```

### 3. Modular Python Package

Import and use TE-LGCN components in your own code:
```python
from te_lgcn.models import TELightGCN
from te_lgcn.training import Trainer
from te_lgcn.evaluation import evaluate_model
```

---

## ğŸ“¦ Installation

### Requirements

- Python 3.8+
- PyTorch 2.0+
- CUDA (optional, for GPU acceleration)

### Install from Source

```bash
# Clone the repository
git clone https://github.com/yourusername/topic-enhanced-lightgcn.git
cd topic-enhanced-lightgcn

# Install dependencies
pip install -r requirements.txt

# Install package in editable mode (recommended for development)
pip install -e .
```

### Dependencies

Core libraries:
- `torch>=2.0.0` - Deep learning framework
- `gensim>=4.0.0` - Doc2Vec and LDA implementation
- `pandas`, `numpy`, `scipy` - Data processing
- `scikit-learn` - Additional ML utilities

---

## ğŸš€ Quick Start

### Option 1: Using Jupyter Notebooks (Recommended for Research)

Follow the execution sequence in [`notebooks/README.md`](notebooks/README.md):

1. **Data Preprocessing**: `notebooks/preprocessing/data_preparation.ipynb`
2. **Feature Extraction**:
   - `notebooks/feature_extraction/doc2vec_embeddings.ipynb`
   - `notebooks/feature_extraction/lda_topics.ipynb`
3. **Baseline**: `notebooks/baselines/lightgcn_baseline.ipynb`
4. **TE-LGCN**: `notebooks/te_lgcn/te_lgcn_k10.ipynb`

### Option 2: Using Python Package

```python
import torch
from te_lgcn.models import TELightGCN
from te_lgcn.training import Trainer
from te_lgcn.evaluation import evaluate_model

# Load your data
# ... (see notebooks for data loading examples)

# Create model
model = TELightGCN(
    n_users=670,
    n_items=3485,
    n_topics=10,              # Number of LDA topics
    dim=64,                   # Embedding dimension
    layers=3,                 # GCN layers
    A_hat=adj_matrix,         # Normalized adjacency matrix
    doc2vec_weights=doc2vec_emb  # Pre-trained Doc2Vec embeddings
).to(device)

# Setup training
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
trainer = Trainer(
    model=model,
    optimizer=optimizer,
    device='cuda',
    lambda1=1e-5,  # L2 regularization weight
    lambda2=1e-3   # Content consistency weight
)

# Train
for epoch in range(50):
    loss = trainer.train_epoch(train_loader)
    results = evaluate_model(model, val_df, user_pos_items, k=10)
    print(f"Epoch {epoch}: Loss={loss:.4f}, Recall@10={results['Recall']:.4f}")
```

---

## ğŸ“ Repository Structure

```
topic-enhanced-lightgcn/
â”œâ”€â”€ te_lgcn/                    # Python package (importable)
â”‚   â”œâ”€â”€ models/                 # LightGCN and TE-LGCN implementations
â”‚   â”œâ”€â”€ data/                   # Dataset, graph construction
â”‚   â”œâ”€â”€ features/               # Doc2Vec and LDA extractors
â”‚   â”œâ”€â”€ training/               # Trainer and loss functions
â”‚   â”œâ”€â”€ evaluation/             # Metrics (Recall, NDCG, Precision)
â”‚   â””â”€â”€ utils/                  # Configuration and logging
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter notebooks organized by research phase
â”‚   â”œâ”€â”€ preprocessing/          # Data preparation and filtering
â”‚   â”œâ”€â”€ feature_extraction/     # Doc2Vec and LDA feature generation
â”‚   â”œâ”€â”€ baselines/              # Baseline LightGCN experiments
â”‚   â””â”€â”€ te_lgcn/                # TE-LGCN experiments (k=7,10,15,20)
â”‚
â”œâ”€â”€ configs/                    # YAML configuration files
â”‚   â”œâ”€â”€ default.yaml            # Default hyperparameters
â”‚   â””â”€â”€ experiments/            # Experiment-specific configs
â”‚
â”œâ”€â”€ data/                       # Data directory (not included in repo)
â”‚   â”œâ”€â”€ raw/                    # Original datasets
â”‚   â”œâ”€â”€ processed/              # Filtered and split data
â”‚   â””â”€â”€ embeddings/             # Doc2Vec embeddings
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ pipeline.md             # Research methodology
â”‚   â””â”€â”€ implementation_summary.md
â”‚
â”œâ”€â”€ results/                    # Experiment results (git-ignored)
â”œâ”€â”€ scripts/                    # CLI scripts (future)
â”œâ”€â”€ tests/                      # Unit tests (future)
â”‚
â”œâ”€â”€ setup.py                    # Package installation
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ .gitignore                  # Git exclusions
â”œâ”€â”€ LICENSE                     # MIT License
â””â”€â”€ README.md                   # This file
```

---

## ğŸ“Š Data

This project uses the **MovieLens dataset** with additional movie plot summaries.

### Dataset Statistics (k=5 filtered)

- **Users**: 671
- **Items**: 3,485
- **Interactions**: 89,927
- **Sparsity**: 96.15%

### Download Data

The actual data files are not included in this repository. Please:

1. Download MovieLens dataset from [GroupLens](https://grouplens.org/datasets/movielens/)
2. Place files in `data/raw/`:
   - `ratings.csv`
   - `movies.csv`
   - `movie_data_final_clean.csv` (plot summaries)
3. Run preprocessing notebook to generate processed data

See [`data/README.md`](data/README.md) for detailed data structure and usage.

---

## âš™ï¸ Hyperparameters

### Default Configuration

| Parameter | Value | Description |
|-----------|-------|-------------|
| `dim` | 64 | Embedding dimension |
| `layers` | 3 | Number of GCN layers |
| `batch_size` | 1024 | Training batch size |
| `lr` | 1e-3 | Learning rate (Adam) |
| `Î»â‚` | 1e-5 | L2 regularization weight |
| `Î»â‚‚` | 1e-3 | Content consistency loss weight |
| `k_core` | 5 | Minimum interactions per user/item |
| `n_topics` | 10 | Number of LDA topics |

### Experiment Configurations

See [`configs/experiments/`](configs/experiments/) for pre-defined configurations:
- `baseline.yaml` - Vanilla LightGCN
- `te_lgcn_k10.yaml` - Full TE-LGCN with 10 topics

---

## ğŸ§ª Experiments

### Baseline Comparison

| Model | Doc2Vec Init | Topic Nodes | Recall@10 | NDCG@10 |
|-------|--------------|-------------|-----------|---------|
| LightGCN | âŒ | âŒ | 0.159 | - |
| LightGCN + Doc2Vec | âœ… | âŒ | ~0.175 | - |
| **TE-LGCN** | âœ… | âœ… | **0.200** | - |

### Ablation Study: Number of Topics

| Topics (k) | Recall@10 | Note |
|------------|-----------|------|
| k=7 | ~0.195 | Fewer topics |
| **k=10** | **~0.200** | **Optimal** |
| k=15 | ~0.198 | More granular |
| k=20 | ~0.196 | Too many topics |

---

## ğŸ“ˆ Evaluation Metrics

Supported metrics (all computed at top-K):
- **Recall@K**: Proportion of relevant items retrieved
- **NDCG@K**: Normalized Discounted Cumulative Gain
- **Precision@K**: Precision of top-K recommendations
- **Hit Rate@K**: Whether any relevant item is in top-K

Default evaluation: K=10

---

## ğŸ› ï¸ Usage Examples

### Training with Custom Data

```python
from te_lgcn.data import build_heterogeneous_graph, RecommendationDataset
from torch.utils.data import DataLoader

# Build graph with topic nodes
adj_matrix = build_heterogeneous_graph(
    train_df,
    topic_df,
    n_users=n_users,
    n_items=n_items,
    n_topics=n_topics
)

# Create dataset
dataset = RecommendationDataset(train_df, n_items)
train_loader = DataLoader(dataset, batch_size=1024, shuffle=True)

# Train model (see Quick Start section)
```

### Using Pre-trained Embeddings

```python
from te_lgcn.features import Doc2VecExtractor
import pickle

# Option 1: Train Doc2Vec
extractor = Doc2VecExtractor(vector_size=64, epochs=20)
doc2vec_weights = extractor.fit_transform(item_documents)

# Option 2: Load pre-trained embeddings
with open('data/embeddings/doc2vec_embeddings_64d.pkl', 'rb') as f:
    data = pickle.load(f)
    doc2vec_weights = torch.FloatTensor(data['embeddings'])
```

### Extracting Topics with LDA

```python
from te_lgcn.features import LDAExtractor

extractor = LDAExtractor(n_topics=10)
topic_df = extractor.fit_transform(item_documents)
# Returns DataFrame: [movie_id, topic_id, probability]
```

---

## ğŸ”¬ Research Methodology

The complete research pipeline is documented in [`docs/pipeline.md`](docs/pipeline.md):

1. **Data Preprocessing**: K-core filtering, leave-one-out splitting
2. **Feature Extraction**: Doc2Vec training, LDA topic modeling
3. **Graph Construction**: Heterogeneous user-item-topic graph
4. **Model Training**: Dual enhancement with content consistency loss
5. **Evaluation**: Multiple metrics on test set

---

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:

- [ ] Add unit tests (`tests/`)
- [ ] Implement CLI scripts (`scripts/train.py`, `scripts/evaluate.py`)
- [ ] Support additional datasets (Amazon, Yelp, etc.)
- [ ] Add more baseline models (NGCF, DGCF, etc.)
- [ ] Hyperparameter tuning with Ray Tune
- [ ] Documentation website (Sphinx)

Please open an issue or pull request for any contributions.

---

## ğŸ“„ Citation

If you use this code in your research, please cite:

```bibtex
@software{te_lgcn_2026,
  title={Topic-Enhanced LightGCN: A Dual Enhancement Strategy for Recommendation},
  author={TE-LGCN Research Team},
  year={2026},
  url={https://github.com/yourusername/topic-enhanced-lightgcn}
}
```

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **LightGCN**: He et al., "LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation", SIGIR 2020
- **MovieLens**: Harper and Konstan, "The MovieLens Datasets", ACM TIIS 2015
- **Gensim**: Å˜ehÅ¯Å™ek and Sojka, "Software Framework for Topic Modelling with Large Corpora", 2010

---

## ğŸ“ Contact

For questions or issues:
- **Issues**: [GitHub Issues](https://github.com/yourusername/topic-enhanced-lightgcn/issues)
- **Email**: your.email@example.com

---

**Built with â¤ï¸ for the recommendation systems research community**
